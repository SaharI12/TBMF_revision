{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import scipy.io as sio\n",
    "\n"
   ],
   "id": "5d042f90b6be3b73",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# GT and phantom loading",
   "id": "80538b3c7ce90145"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Mask path",
   "id": "2cf984207d76a689"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mask_path = \"/Dinor_revision/new_phantom/new_phantom_data/80_by_80_segmented_3D_masks_test/scan12.h5\"\n",
    "mask_h5 = h5py.File(mask_path,'r')\n",
    "print(mask_h5.keys())\n",
    "mask = mask_h5['masks'][:]\n",
    "mask = mask.astype(np.float32)  # or np.float64\n",
    "mask[mask == 0] = np.nan\n",
    "print(mask.shape)\n",
    "\n"
   ],
   "id": "1b38ba98a9f783ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mask_3D = \"/home/sahar/Models/phantom_data/new_B0_data/masks_80/scan12_masks.h5\"\n",
    "mask_3D = h5py.File(mask_3D,'r')\n",
    "print(mask_3D.keys())\n",
    "mask_3D = mask_3D['mask'][:]\n",
    "mask_3D = np.transpose(mask_3D,(2,0,1))\n",
    "mask_3D = mask_3D.astype(np.float32)\n",
    "mask_3D[mask_3D == 0] = np.nan\n",
    "print(mask_3D.shape)\n",
    "plt.imshow(mask_3D[5])\n"
   ],
   "id": "b0f972044f3a559a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "create a 4D GT dataset",
   "id": "1b553f33ea1185ef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Bpath\n",
    "b_path = \"/Dinor_revision/new_phantom/dinor_train/code_addition/phanton_comp/scan12_B_pred.h5\"\n",
    "#\"/home/sahar/Models/phantom_data/new_B0_data/dataset_80/B_maps.h5\"\n",
    "b = h5py.File(b_path, 'r')\n",
    "keys = list(b.keys())\n",
    "data_1 = b[keys[-1]][:]\n",
    "b_maps = np.transpose(data_1, (0,3,1,2))\n",
    "b0_gt = b_maps[0,:,:,:] * mask\n",
    "b1_gt = b_maps[1,:,:,:] * mask\n",
    "b1_gt_display = b_maps[1,:,:,:] * mask_3D\n",
    "b0_gt_display = b_maps[0,:,:,:] * mask_3D\n",
    "print(b0_gt.shape, b1_gt.shape)\n",
    "print(b_maps.shape)\n",
    "print(data_1.shape)\n",
    "# Kswap axes\n",
    "ksw_path = \"/Dinor_revision/new_phantom/new_phantom_data/maps_80/ksw_maps_3D_test/scan12.h5\"\n",
    "ksw_h5 = h5py.File(ksw_path,'r')\n",
    "keys = list(ksw_h5.keys())\n",
    "ksw_gt = ksw_h5[keys[-1]][:] * mask\n",
    "print(ksw_gt.shape)\n",
    "# fs masp\n",
    "fs_path = \"/Dinor_revision/new_phantom/new_phantom_data/maps_80/fs_maps_3D_test/scan12.h5\"\n",
    "fs_h5 = h5py.File(fs_path,'r')\n",
    "keys = list(fs_h5.keys())\n",
    "fs_gt = fs_h5[keys[-1]][:] * mask\n",
    "print(fs_gt.shape)\n",
    "# T1 path\n",
    "t1_path = \"/Dinor_revision/new_phantom/new_phantom_data/maps_80/T1_maps_3D_test/scan12.h5\"\n",
    "t1_h5 = h5py.File(t1_path,'r')\n",
    "keys = list(t1_h5.keys())\n",
    "t1_gt = t1_h5[keys[-1]][:] * mask\n",
    "print(t1_gt.shape)\n",
    "# T2 path\n",
    "t2_path = \"/Dinor_revision/new_phantom/new_phantom_data/maps_80/T2_maps_3D_test/scan12.h5\"\n",
    "t2_h5 = h5py.File(t2_path,'r')\n",
    "keys = list(t2_h5.keys())\n",
    "t2_gt = t2_h5[keys[-1]][:] * mask\n",
    "print(t2_gt.shape)\n",
    "\n",
    "fig, ax = plt.subplots(1,6, figsize=(20,5))\n",
    "ax[0].imshow(ksw_gt[10,:,:], cmap='viridis')\n",
    "\n",
    "ax[1].imshow(fs_gt[10,:,:], cmap='viridis')\n",
    "ax[2].imshow(b0_gt[10,:,:], cmap='viridis')\n",
    "ax[3].imshow(b1_gt[10,:,:], cmap='viridis')\n",
    "ax[4].imshow(t1_gt[10,:,:], cmap='viridis')\n",
    "ax[5].imshow(t2_gt[10,:,:], cmap='viridis')\n",
    "\n",
    "gt = np.stack((ksw_gt, fs_gt, b0_gt, b1_gt, t1_gt, t2_gt), axis=0)\n",
    "gt_disp = np.stack((ksw_gt, fs_gt, b0_gt_display, b1_gt_display, t1_gt, t2_gt), axis=0)\n",
    "print(gt.shape)\n",
    "\n",
    "with h5py.File('/home/sahar/Models/Dinor_revision/new_phantom/dinor_train/code_addition/phanton_comp/scan12_gt.h5', 'w') as f:\n",
    "    f.create_dataset('gt', data=gt, compression=\"gzip\")\n",
    "    f.create_dataset('gt_disp', data=gt_disp, compression=\"gzip\")\n",
    "\n",
    "for i in range(6):\n",
    "    print(f\"Parameter {i} max value gt {np.nanmax(gt[i,:,:,:])}\")\n"
   ],
   "id": "8e4a696442f9366d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Pred ksw, fs\n",
    "path = \"/comp/fs_ksw_out/y_pred_4D_masked_scaled.h5\"\n",
    "data = h5py.File(path,'r')\n",
    "print(data.keys())\n",
    "data = data['predictions'][:]\n",
    "fs = data[:12,0,:,:]\n",
    "fs[fs < 1] = np.nan\n",
    "ksw = data[:12,1,:,:]\n",
    "ksw[ksw < 1] = np.nan\n",
    "print(f\"fs shape: {fs.shape}, ksw shape: {ksw.shape}\")\n",
    "\n",
    "# Gt ksw and fs\n",
    "fs_gt_path = \"/comp/fs_maps_3D_test/scan12.h5\"\n",
    "fs_gt_h5 = h5py.File(fs_gt_path,'r')\n",
    "keys = list(fs_gt_h5.keys())\n",
    "fs_gt = fs_gt_h5[keys[-1]][:]\n",
    "fs_gt = fs_gt[:12,:,:]\n",
    "fs_gt[fs_gt == 0] = np.nan\n",
    "\n",
    "ksw_gt_path = \"/comp/ksw_maps_3D_test/scan12.h5\"\n",
    "ksw_gt_h5 = h5py.File(ksw_gt_path,'r')\n",
    "keys = list(ksw_gt_h5.keys())\n",
    "ksw_gt = ksw_gt_h5[keys[-1]][:]\n",
    "ksw_gt = ksw_gt[:12,:,:]\n",
    "ksw_gt[ksw_gt == 0] = np.nan\n",
    "print(f\"ksw gt shape {ksw_gt.shape}, fs gt shape: {fs_gt.shape} \")\n",
    "# Pred T\n",
    "path_T = \"/comp/T1_out/y_pred_4D_T1_T2_scaled.h5\"\n",
    "data_T = h5py.File(path_T,'r')\n",
    "print(data_T.keys())\n",
    "data_T = data_T['predictions'][:]\n",
    "print(data_T.shape)\n",
    "t1 = data_T[:12,0,:,:]\n",
    "t1[t1 < 2] = np.nan\n",
    "t2 = data_T[:12,1,:,:]\n",
    "t2[t2 < 2] = np.nan\n",
    "print(f\"T1 shape: {t1.shape}, T2 shape: {t2.shape}\")\n",
    "\n",
    "# GT T1 and T2 for tbmf\n",
    "target_T = \"/home/sahar/Models/comp/T1_out/y_targets_4D_T1_T2_scaled.h5\"\n",
    "t_data = h5py.File(target_T,'r')\n",
    "print(t_data.keys())\n",
    "t_data = t_data['targets'][:]\n",
    "print(t_data.shape)\n",
    "t1_gt = t_data[:12,0,:,:]* mask_3D\n",
    "t1_gt[t1_gt == 0] = np.nan\n",
    "t2_gt = t_data[:12,1,:,:]* mask_3D\n",
    "t2_gt[t2_gt == 0] = np.nan\n",
    "print(f\"T1_gt shape: {t1_gt.shape}, T2_gt shape: {t2_gt.shape}\")\n",
    "\n",
    "\n",
    "\n",
    "path_B = \"/comp/B_out/y_pred_4D_B0_B1_scaled.h5\"\n",
    "data_B = h5py.File(path_B,'r')\n",
    "print(data_B.keys())\n",
    "data_B = data_B['predictions'][:]\n",
    "print(data_B.shape)\n",
    "b0 = data_B[:12,0,:,:] * mask\n",
    "b0_display = data_B[:12,0,:,:] * mask_3D\n",
    "b1 = data_B[:12,1,:,:] * mask\n",
    "b1_display = data_B[:12,1,:,:] * mask_3D\n",
    "print(f\"B0 shape: {b0.shape}, B1 shape: {b1.shape}\")\n",
    "\n",
    "tbmf = np.stack((ksw, fs, b0, b1, t1, t2), axis=0)\n",
    "tbmf_display = np.stack((ksw, fs,b0_display, b1_display, t1, t2), axis=0)\n",
    "tbmf_gt = np.stack((ksw_gt,fs_gt, b0_gt, b1_gt, t1_gt, t2_gt), axis=0)\n",
    "print(f\"tbmf shape: {tbmf.shape}, tbmf_gt.shape = {tbmf_gt.shape}\")\n",
    "\n",
    "with h5py.File(\"/home/sahar/Models/Dinor_revision/new_phantom/dinor_train/code_addition/phanton_comp/tbmf.h5\",'w') as f:\n",
    "    f.create_dataset(\"tmbf\", data=tbmf, compression=\"gzip\")\n",
    "    f.create_dataset(\"tbmf_gt\", data=tbmf_gt, compression=\"gzip\")\n",
    "#\n",
    "fig, ax = plt.subplots(3,6, figsize=(20,5))\n",
    "for i in range(6):\n",
    "    ax[0,i].imshow(tbmf[i,10,:,:] , cmap='viridis')\n",
    "    ax[1,i].imshow(tbmf_gt[i,10,:,:], cmap='viridis')\n",
    "    ax[2,i].imshow(tbmf_display[i,10,:,:], cmap='viridis')\n",
    "    print(f\"Parameter {i} max value pred {np.nanmax(tbmf[i,:,:,:])}, gt- {np.nanmax(tbmf_gt[i,:,:,:])}\")\n"
   ],
   "id": "21987db96a8dec95",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import scipy.ndimage as ndimage\n",
    "from scipy.ndimage import center_of_mass, shift\n",
    "\n",
    "\n",
    "def rotate_image(image, axes=(1,2), k =1):\n",
    "    # option to rotate the image along different axes with variaty of k\n",
    "    return ndimage.rotate(image, angle=90*k, axes=axes, reshape=False, order=0)\n",
    "\n"
   ],
   "id": "dc01077c6712c1d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Config",
   "id": "d24b17fd833dd326"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "config = {\n",
    "    \"save_path\" :\"/home/sahar/Models/Dinor_revision/new_phantom/dinor_train/code_addition/phanton_comp\",\n",
    "    \"nikita_image_size\" : (6,80,12,80),\n",
    "    \"alex_image_size\" : (2,80,12,80)\n",
    "\n",
    "}"
   ],
   "id": "80f2ad5476089bb2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Nikitas methods:",
   "id": "6075e6c8ea33bf8f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# Nikita 6:\n",
    "nikita6_path = \"/Dinor_revision/new_phantom/dinor_train/code_addition/phanton_comp/nikita/phantoms/phantoms_demo6/qmaps.mat\"\n",
    "nikita6 = sio.loadmat(nikita6_path)\n",
    "print(nikita6.keys())\n",
    "maps = ['ksw','fs','b0_inhom','','t1w','t2w']\n",
    "y_nikita6 = np.zeros((6,80,12,80))\n",
    "\n",
    "for i,map  in enumerate(maps):\n",
    "    if map == '':\n",
    "        continue\n",
    "    y_nikita6[i,:,:,:] = nikita6[map]\n",
    "    print(f\"for map {map}, min: {np.min(y_nikita6[i,:,:,:])}, max: {np.max(y_nikita6[i,:,:,:])}\")\n",
    "\n",
    "y_nikita6 = np.transpose(y_nikita6, (0,2,1,3))\n",
    "y_nikita_6_masked = np.zeros(y_nikita6.shape)\n",
    "y_nikita_6_display = np.zeros(y_nikita6.shape)\n",
    "print(f\"y nikita6 shape: {y_nikita6.shape}, ymasked sahpe: {y_nikita_6_masked.shape}\")\n",
    "#\n",
    "for i in range(y_nikita6.shape[0]):\n",
    "    y_nikita_6_masked[i] = y_nikita6[i] * mask[:,:,:]\n",
    "    if i ==2:\n",
    "        y_nikita_6_display[i,:,:,:] = y_nikita6[i] * mask_3D\n",
    "    else:\n",
    "        y_nikita_6_display[i,:,:,:] = y_nikita6[i,:,:,:] * mask[:,:,:]\n",
    "\n",
    "fig, ax = plt.subplots(2,6, figsize=(20,5))\n",
    "for i in range(6):\n",
    "    ax[0,i].imshow(y_nikita_6_masked[i,10,:,:] , cmap='viridis')\n",
    "    ax[1,i].imshow(y_nikita6[i,10,:,:], cmap='viridis')\n",
    "\n",
    "with h5py.File(os.path.join(config['save_path'], f'nikita_6.h5'), 'w') as f:\n",
    "    f.create_dataset('y_pred', data=y_nikita6)\n",
    "    f.create_dataset('y_pred_masked', data=y_nikita_6_masked)\n",
    "\n",
    "print(y_nikita6.shape)\n",
    "\n",
    "# Nikita 30 :\n",
    "nikita30_path = \"/Dinor_revision/new_phantom/dinor_train/code_addition/phanton_comp/nikita/phantoms/phantoms_demo/qmaps.mat\"\n",
    "nikita30 = sio.loadmat(nikita30_path)\n",
    "print(nikita30.keys())\n",
    "y_nikita30 = np.zeros(config['nikita_image_size'])\n",
    "\n",
    "for i,map  in enumerate(maps):\n",
    "    if map == '':\n",
    "        continue\n",
    "    y_nikita30[i,:,:,:] = nikita30[map]\n",
    "    print(f\"for map {map}, min: {np.min(y_nikita30[i,:,:,:])}, max: {np.max(y_nikita30[i,:,:,:])}\")\n",
    "\n",
    "\n",
    "y_nikita30 = np.transpose(y_nikita30, (0,2,1,3))\n",
    "y_nikita_30_masked = np.zeros(y_nikita30.shape)\n",
    "y_nikita_30_display = np.zeros(y_nikita30.shape)\n",
    "\n",
    "for i in range(y_nikita30.shape[0]):\n",
    "    y_nikita_30_masked[i] = y_nikita30[i] * mask\n",
    "    if i==2:\n",
    "        y_nikita_30_display[i,:,:,:] = y_nikita30[i] * mask_3D\n",
    "    else:\n",
    "        y_nikita_30_display[i,:,:,:] = y_nikita30[i,:,:,:] * mask\n",
    "\n",
    "with h5py.File(os.path.join(config['save_path'], f'nikita_30.h5'), 'w') as f:\n",
    "    f.create_dataset('y_pred', data=y_nikita30)\n",
    "    f.create_dataset('y_pred_masked', data=y_nikita_30_masked)\n",
    "print(y_nikita6.shape)\n",
    "\n",
    "fig, ax = plt.subplots(3,6, figsize=(20,8))\n",
    "for i in range(6):\n",
    "    im0 = ax[0,i].imshow(y_nikita_30_masked[i,10,:,:], cmap='viridis')\n",
    "    im1 = ax[1,i].imshow(y_nikita30[i,10,:,:], cmap='viridis')\n",
    "    im2 = ax[2,i].imshow(gt[i,10,:,:], cmap=\"viridis\")\n",
    "\n",
    "    # Add colorbars\n",
    "    plt.colorbar(im0, ax=ax[0,i], shrink=0.6)\n",
    "    plt.colorbar(im1, ax=ax[1,i], shrink=0.6)\n",
    "    plt.colorbar(im2, ax=ax[2,i], shrink=0.6)\n",
    "\n",
    "    # Optional: Add titles for clarity\n",
    "    if i < len(maps) and maps[i] != '':\n",
    "        ax[0,i].set_title(f'{maps[i]} (masked)')\n",
    "        ax[1,i].set_title(f'{maps[i]} (unmasked)')\n",
    "        ax[2,i].set_title(f'{maps[i]} (ground truth)')\n",
    "\n",
    "plt.tight_layout()\n"
   ],
   "id": "64e32e0be225ab42",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#Alex dataset",
   "id": "d286fb5d1f63e232"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Alex nbmf 6:\n",
    "maps_alex = ['kb_T', 'fb_T']\n",
    "alex_nbmf_6_path = f\"/Dinor_revision/new_phantom/dinor_train/code_addition/phanton_comp/alex/nbmf_phantom_6.h5\"\n",
    "alex_nbmf_6_file = h5py.File(alex_nbmf_6_path, 'r')\n",
    "\n",
    "print(alex_nbmf_6_file.keys())\n",
    "y_alex_nbmf_6 = np.zeros(config['alex_image_size'])\n",
    "\n",
    "for i,map  in enumerate(maps_alex):\n",
    "    # handle Nan values if any\n",
    "    if np.any(np.isnan(alex_nbmf_6_file[map][:])):\n",
    "        print(f\"Warning: NaN values found in map {map}. Replacing NaNs with zeros.\")\n",
    "        y_alex_nbmf_6[i,:,:,:] = np.nan_to_num(alex_nbmf_6_file[map][:], nan=0.0)\n",
    "    else:\n",
    "        y_alex_nbmf_6[i,:,:,:] = alex_nbmf_6_file[map][:]\n",
    "    print(f\"for map {map}, min: {np.min(y_alex_nbmf_6[i,:,:,:])}, max: {np.max(y_alex_nbmf_6[i,:,:,:])}\")\n",
    "\n",
    "y_alex_nbmf_6 = np.transpose(y_alex_nbmf_6, (0,2,1,3))\n",
    "y_alex_nbmf_6_masked= np.zeros(y_alex_nbmf_6.shape)\n",
    "\n",
    "for i in range(y_alex_nbmf_6.shape[0]):\n",
    "    y_alex_nbmf_6_masked[i,:,:,:] = y_alex_nbmf_6[i,:,:,:] * mask[:,:,:]\n",
    "\n",
    "\n",
    "with h5py.File(os.path.join(config['save_path'], f'alex_nbmf_6.h5'), 'w') as f:\n",
    "    f.create_dataset('y_pred', data=y_alex_nbmf_6)\n",
    "    f.create_dataset('y_pred_masked', data=y_alex_nbmf_6_masked)\n",
    "\n",
    "print(f\" shape of nbmf :{y_alex_nbmf_6.shape}\")\n",
    "#\n",
    "# fig, ax = plt.subplots(2,2, figsize=(10,5))\n",
    "# for i in range(2):\n",
    "#     ax[0,i].imshow(y_alex_nbmf_6[i,10,:,:] , cmap='viridis')\n",
    "#     ax[1,i].imshow(y_alex_nbmf_6_masked[i,10,:,:]*110e3/3, cmap='viridis')\n",
    "\n",
    "\n",
    "# Alex nbmf 30:\n",
    "alex_nbmf_30_path = f\"/Dinor_revision/new_phantom/dinor_train/code_addition/phanton_comp/alex/nbmf_phantom_30.h5\"\n",
    "alex_nbmf_30_file = h5py.File(alex_nbmf_30_path, 'r')\n",
    "print(alex_nbmf_30_file.keys())\n",
    "y_alex_nbmf_30 = np.zeros(config['alex_image_size'])\n",
    "\n",
    "for i,map  in enumerate(maps_alex):\n",
    "    if np.any(np.isnan(alex_nbmf_30_file[map][:])):\n",
    "        print(f\"Warning: NaN values found in map {map}. Replacing NaNs with zeros.\")\n",
    "        y_alex_nbmf_30[i,:,:,:] = np.nan_to_num(alex_nbmf_30_file[map][:], nan=0.0)\n",
    "    else:\n",
    "        y_alex_nbmf_30[i,:,:,:] = alex_nbmf_30_file[map][:]\n",
    "    print(f\"for map {map}, min: {np.min(y_alex_nbmf_30[i,:,:,:])}, max: {np.max(y_alex_nbmf_30[i,:,:,:])}\")\n",
    "\n",
    "y_alex_nbmf_30 = np.transpose(y_alex_nbmf_30, (0,2,1,3))\n",
    "y_alex_nbmf_30_masked = np.zeros(y_alex_nbmf_30.shape)\n",
    "\n",
    "for i in range(y_alex_nbmf_30.shape[0]):\n",
    "    y_alex_nbmf_30_masked[i,:,:,:] = y_alex_nbmf_30[i,:,:,:] * mask[:,:,:]\n",
    "\n",
    "with h5py.File(os.path.join(config['save_path'], f'alex_nbmf_30.h5'), 'w') as f:\n",
    "    f.create_dataset('y_pred', data=y_alex_nbmf_30)\n",
    "    f.create_dataset('y_pred_masked', data=y_alex_nbmf_30_masked)\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots(3,2, figsize=(10,5))\n",
    "# for i in range(2):\n",
    "#     im0 = ax[0,i].imshow(y_alex_nbmf_30_masked[i,10,:,:], cmap='viridis')\n",
    "#     im1 = ax[1,i].imshow(y_alex_nbmf_30[i,10,:,:], cmap='viridis')\n",
    "#     im2 = ax[2,i].imshow(gt[i,10,:,:], cmap=\"viridis\")\n",
    "#\n",
    "#     # Add colorbars\n",
    "#     plt.colorbar(im0, ax=ax[0,i], shrink=0.6)\n",
    "#     plt.colorbar(im1, ax=ax[1,i], shrink=0.6)\n",
    "#     plt.colorbar(im2, ax=ax[2,i], shrink=0.6)\n",
    "#\n",
    "#     # Optional: Add titles for clarity\n",
    "#     if i < len(maps) and maps[i] != '':\n",
    "#         ax[0,i].set_title(f'{maps[i]} (masked)')\n",
    "#         ax[1,i].set_title(f'{maps[i]} (unmasked)')\n",
    "#         ax[2,i].set_title(f'{maps[i]} (ground truth)')\n",
    "#\n",
    "# plt.tight_layout()\n",
    "# print(y_alex_nbmf_30.shape)\n",
    "# #\n",
    "#\n",
    "# Alex vbmf 6:\n",
    "alex_vbmf_6_path = f\"/Dinor_revision/new_phantom/dinor_train/code_addition/phanton_comp/alex/vbmf_phantom-larg2_6.h5\"\n",
    "alex_vbmf_6_file = h5py.File(alex_vbmf_6_path, 'r')\n",
    "print(alex_vbmf_6_file.keys())\n",
    "\n",
    "y_alex_vbmf_6 = np.zeros(config['alex_image_size'])\n",
    "for i,map  in enumerate(maps_alex):\n",
    "    if np.any(np.isnan(alex_vbmf_6_file[map][:])):\n",
    "        print(f\"Warning: NaN values found in map {map}. Replacing NaNs with zeros.\")\n",
    "        y_alex_vbmf_6[i,:,:,:] = np.nan_to_num(alex_vbmf_6_file[map][:], nan=0.0)\n",
    "    else:\n",
    "        y_alex_vbmf_6[i,:,:,:] = alex_vbmf_6_file[map][:]\n",
    "    print(f\"for map {map}, min: {np.min(y_alex_vbmf_6[i,:,:,:])}, max: {np.max(y_alex_vbmf_6[i,:,:,:])}\")\n",
    "\n",
    "y_alex_vbmf_6 = np.transpose(y_alex_vbmf_6, (0,2,1,3))\n",
    "y_alex_vbmf_6_masked = np.zeros(y_alex_vbmf_6.shape)\n",
    "\n",
    "for i in range(y_alex_vbmf_6.shape[0]):\n",
    "    y_alex_vbmf_6_masked[i,:,:,:] = y_alex_vbmf_6[i,:,:,:]* mask\n",
    "\n",
    "\n",
    "with h5py.File(os.path.join(config['save_path'], f'alex_vbmf_6.h5'), 'w') as f:\n",
    "    f.create_dataset('y_pred', data=y_alex_vbmf_6)\n",
    "    f.create_dataset('y_pred_masked', data=y_alex_vbmf_6_masked)\n",
    "print(y_alex_vbmf_6.shape)\n",
    "\n",
    "# fig, ax = plt.subplots(3,2, figsize=(10,5))\n",
    "# for i in range(2):\n",
    "#     im0 = ax[0,i].imshow(y_alex_vbmf_6_masked[i,10,:,:], cmap='viridis')\n",
    "#     im1 = ax[1,i].imshow(y_alex_vbmf_6[i,10,:,:], cmap='viridis')\n",
    "#     im2 = ax[2,i].imshow(gt[i,10,:,:], cmap=\"viridis\")\n",
    "#\n",
    "#     # Add colorbars\n",
    "#     plt.colorbar(im0, ax=ax[0,i], shrink=0.6)\n",
    "#     plt.colorbar(im1, ax=ax[1,i], shrink=0.6)\n",
    "#     plt.colorbar(im2, ax=ax[2,i], shrink=0.6)\n",
    "#\n",
    "#     # Optional: Add titles for clarity\n",
    "#     if i < len(maps) and maps[i] != '':\n",
    "#         ax[0,i].set_title(f'{maps[i]} (masked)')\n",
    "#         ax[1,i].set_title(f'{maps[i]} (unmasked)')\n",
    "#         ax[2,i].set_title(f'{maps[i]} (ground truth)')\n",
    "#\n",
    "# plt.tight_layout()\n",
    "# print(y_alex_nbmf_30.shape)\n",
    "\n",
    "\n",
    "#\n",
    "#\n",
    "# Alex vbmf 30:\n",
    "alex_vbmf_30_path = f\"/Dinor_revision/new_phantom/dinor_train/code_addition/phanton_comp/alex/vbmf_phantom-larg2_30.h5\"\n",
    "alex_vbmf_30_file = h5py.File(alex_vbmf_30_path, 'r')\n",
    "print(alex_vbmf_30_file.keys())\n",
    "\n",
    "y_alex_vbmf_30 = np.zeros(config['alex_image_size'])\n",
    "\n",
    "for i,map  in enumerate(maps_alex):\n",
    "    if np.any(np.isnan(alex_vbmf_30_file[map][:])):\n",
    "        print(f\"Warning: NaN values found in map {map}. Replacing NaNs with zeros.\")\n",
    "        y_alex_vbmf_30[i,:,:,:] = np.nan_to_num(alex_vbmf_30_file[map][:], nan=0.0)\n",
    "    else:\n",
    "        y_alex_vbmf_30[i,:,:,:] = alex_vbmf_30_file[map][:]\n",
    "    print(f\"for map {map}, min: {np.min(y_alex_vbmf_30[i,:,:,:])}, max: {np.max(y_alex_vbmf_30[i,:,:,:])}, shape of original: {alex_vbmf_30_file[map][:].shape}\")\n",
    "\n",
    "y_alex_vbmf_30 = np.transpose(y_alex_vbmf_30, (0,2,1,3))\n",
    "y_alex_vbmf_30_masked= np.zeros(y_alex_vbmf_30.shape)\n",
    "#\n",
    "for i in range(y_alex_vbmf_30.shape[0]):\n",
    "    y_alex_vbmf_30_masked[i,:,:,:] = y_alex_vbmf_30[i,:,:,:] * mask\n",
    "\n",
    "with h5py.File(os.path.join(config['save_path'], f'alex_vbmf_30.h5'), 'w') as f:\n",
    "    f.create_dataset('y_pred', data=y_alex_vbmf_30)\n",
    "    f.create_dataset('y_pred_masked', data=y_alex_vbmf_30_masked)\n",
    "print(y_alex_vbmf_30.shape)\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots(3,2, figsize=(10,5))\n",
    "# for i in range(2):\n",
    "#     im0 = ax[0,i].imshow(y_alex_vbmf_6_masked[i,10,:,:], cmap='viridis')\n",
    "#     im1 = ax[1,i].imshow(y_alex_vbmf_6[i,10,:,:], cmap='viridis')\n",
    "#     im2 = ax[2,i].imshow(gt[i,10,:,:], cmap=\"viridis\")\n",
    "#\n",
    "#     # Add colorbars\n",
    "#     plt.colorbar(im0, ax=ax[0,i], shrink=0.6)\n",
    "#     plt.colorbar(im1, ax=ax[1,i], shrink=0.6)\n",
    "#     plt.colorbar(im2, ax=ax[2,i], shrink=0.6)\n",
    "#\n",
    "#     # Optional: Add titles for clarity\n",
    "#     if i < len(maps) and maps[i] != '':\n",
    "#         ax[0,i].set_title(f'{maps[i]} (masked)')\n",
    "#         ax[1,i].set_title(f'{maps[i]} (unmasked)')\n",
    "#         ax[2,i].set_title(f'{maps[i]} (ground truth)')\n",
    "#\n",
    "# plt.tight_layout()\n",
    "# print(y_alex_nbmf_30.shape)\n",
    "\n"
   ],
   "id": "e4b95f0b012b7077",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Display figure",
   "id": "680733a651937bad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from transformer_architecture_prod import *\n",
    "from human.functions_prod import *\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib import cm\n",
    "\n",
    "def create_cmaps() -> list:\n",
    "    # Define colormaps (using your existing ones)\n",
    "    buda_map = LinearSegmentedColormap.from_list('buda', cm_data_vik)\n",
    "    lipari_map = LinearSegmentedColormap.from_list('lipari', cm_data_brok)\n",
    "\n",
    "    original_map = plt.get_cmap('viridis')\n",
    "    color_mat = original_map(np.arange(original_map.N))\n",
    "    color_mat[0, 0:3] = 0  # minimum value is set to black\n",
    "    b_viridis = mcolors.LinearSegmentedColormap.from_list('colormap', color_mat)\n",
    "\n",
    "    original_map = buda_map\n",
    "    color_mat = original_map(np.arange(original_map.N))\n",
    "    color_mat[0, 0:3] = 0  # minimum value is set to black\n",
    "    b_bwr = mcolors.LinearSegmentedColormap.from_list('colormap', color_mat)\n",
    "\n",
    "    original_map = lipari_map\n",
    "    color_mat = original_map(np.arange(original_map.N))\n",
    "    color_mat[0, 0:3] = 0  # minimum value is set to black\n",
    "    b_rdgy = mcolors.LinearSegmentedColormap.from_list('colormap', color_mat)\n",
    "\n",
    "    original_map = plt.get_cmap('winter')\n",
    "    color_mat = original_map(np.arange(original_map.N))\n",
    "    color_mat[0, 0:3] = 0  # minimum value is set to black\n",
    "    winter = mcolors.LinearSegmentedColormap.from_list('colormap', color_mat)\n",
    "\n",
    "    original_map = plt.get_cmap('hot')\n",
    "    color_mat = original_map(np.arange(original_map.N))\n",
    "    color_mat[0, 0:3] = 0  # minimum value is set to black\n",
    "    b_hot = mcolors.LinearSegmentedColormap.from_list('colormap', color_mat)\n",
    "\n",
    "    # Convert 'magma' string to proper colormap object\n",
    "    magma_cmap = plt.get_cmap('magma')\n",
    "\n",
    "    # Use your existing colormaps\n",
    "    cbar_list = [magma_cmap, b_viridis, b_bwr, b_rdgy, b_hot, winter]\n",
    "    return cbar_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "450b45a97f4e4953",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, axs = plt.subplots(nrows=8, ncols=6, figsize=(30, 18))\n",
    "fig.patch.set_facecolor('black')# Set black background\n",
    "for i in range(8):\n",
    "    for j in range(6):\n",
    "        axs[i, j].set_facecolor('black')\n",
    "\n",
    "cbar_list = create_cmaps()\n",
    "# Define value ranges for each parameter\n",
    "vmin = [0, 0, -0.6, 0.5, 2200, 400]\n",
    "vmax = [1400, 120, 0.6, 1.5, 3400, 1000]\n",
    "\n",
    "column_titles = [\n",
    "    r\"$K_{ssw}$ (S$^{-1}$)\",\n",
    "    r\"$f_s$ (%)\",\n",
    "    r\"$B_0$ (ppm)\",\n",
    "    r\"$B_1$ (rel.)\",\n",
    "    r\"$T_1$ (ms)\",\n",
    "    r\"$T_2$ (ms)\"\n",
    "]\n",
    "\n",
    "\n",
    "# Rotate TMBF data to align with other methods\n",
    "tbmf_rotated = np.rot90(tbmf, k=1, axes=(2, 3))  # Rotate 90 degrees counterclockwise\n",
    "tbmf_rotated_flipped = np.flip(tbmf_rotated, axis=2)  # Flip vertically\n",
    "\n",
    "# Create a copy of the original tbmf for selective rotation\n",
    "tbmf_selective = tbmf_rotated_flipped.copy()\n",
    "\n",
    "# Keep the original (non-rotated) data for B0 and B1 (indices 2 and 3)\n",
    "tbmf_selective[2] = tbmf[2]  # B0 - keep original\n",
    "tbmf_selective[3] = tbmf[3]  # B1 - keep original\n",
    "\n",
    "# Rotate TMBF data to align with other methods\n",
    "tbmf_rotated1 = np.rot90(tbmf_display, k=1, axes=(2, 3))  # Rotate 90 degrees counterclockwise\n",
    "tbmf_rotated_flipped1 = np.flip(tbmf_rotated1, axis=2)  # Flip vertically\n",
    "\n",
    "# Create a copy of the original tbmf for selective rotation\n",
    "tbmf_selective_display = tbmf_rotated_flipped.copy()\n",
    "\n",
    "# Keep the original (non-rotated) data for B0 and B1 (indices 2 and 3)\n",
    "tbmf_selective_display[2] = tbmf_display[2]  # B0 - keep original\n",
    "tbmf_selective_display[3] = tbmf_display[3]  # B1 - keep original\n",
    "\n",
    "with h5py.File(\"/home/sahar/Models/Dinor_revision/new_phantom/dinor_train/code_addition/phanton_comp/tbmf_rotated.h5\", 'w') as f:\n",
    "    f.create_dataset(\"tbmf\", data = tbmf_selective)\n",
    "\n",
    "# Update the data_list to use selectively rotated TMBF\n",
    "data_list = [gt_disp, tbmf_selective_display, y_nikita_6_display, y_nikita_30_display, y_alex_nbmf_6_masked, y_alex_nbmf_30_masked, y_alex_vbmf_6_masked, y_alex_vbmf_30_masked]\n",
    "\n",
    "row_titles = [\"GT\", \"TBMF\", \"dot-6\", \"dot-30\", \"NBMf 6\", \"NBMf 30\", \"VBMF 6\", \"VBMF 30\"]\n",
    "\n",
    "scale_factor_alex = [1, 110e3/3]\n",
    "scale_factor_nikita = [1, 110e3/3, 1, 1, 1000, 1000]\n",
    "index = 10\n",
    "mask_index = 8\n",
    "# Main plotting loop\n",
    "for i in range(8):\n",
    "    curr_data = data_list[i]\n",
    "\n",
    "    for j in range(6):\n",
    "        # Set column titles only for the first row\n",
    "        if i == 0:\n",
    "            axs[i, j].set_title(column_titles[j], fontsize=20, color='white', pad=20)\n",
    "\n",
    "        # Display the image\n",
    "        if i < 2:  # GT and TMBF\n",
    "            if j==2 or j==3:\n",
    "                img = axs[i, j].imshow(curr_data[j, index, :, :]*mask_3D[mask_index] , cmap=cbar_list[j], vmin=vmin[j], vmax=vmax[j])\n",
    "            else:\n",
    "                img = axs[i, j].imshow(curr_data[j, index, :, :] , cmap=cbar_list[j], vmin=vmin[j], vmax=vmax[j])\n",
    "\n",
    "        elif i >= 4:  # Alex methods\n",
    "            if j < curr_data.shape[0]:  # Only plot if the map exists\n",
    "                img = axs[i, j].imshow(curr_data[j, index, :, :] * scale_factor_alex[j], cmap=cbar_list[j], vmin=vmin[j], vmax=vmax[j])\n",
    "            else:\n",
    "                # Display blank/black image for missing maps\n",
    "                axs[i, j].imshow(np.zeros((80, 80)), cmap='gray', vmin=0, vmax=1)\n",
    "\n",
    "        else:  # Nikita methods (rows 2 and 3: dot_6 and dot_30)\n",
    "            if j == 0:\n",
    "                data = (curr_data[j,index, :, :]*scale_factor_nikita[j])\n",
    "                cmap = cbar_list[j]\n",
    "                if isinstance(cmap, str):\n",
    "                    cmap = plt.get_cmap(cmap)\n",
    "                cmap.set_bad('black')\n",
    "                img = axs[i, j].imshow(data, cmap=cmap, vmin=vmin[j], vmax=vmax[j])\n",
    "\n",
    "            elif j == 1:\n",
    "                data = curr_data[j, index, :, :]*scale_factor_nikita[j]\n",
    "                cmap = cbar_list[j]\n",
    "                if isinstance(cmap, str):\n",
    "                    cmap = plt.get_cmap(cmap)\n",
    "                cmap.set_bad('black')\n",
    "                img = axs[i, j].imshow(data, cmap=cmap, vmin=vmin[j], vmax=vmax[j])\n",
    "\n",
    "            elif j == 2:\n",
    "                data = (curr_data[j, index, :,: ]*scale_factor_nikita[j])\n",
    "                cmap = cbar_list[j]\n",
    "                if isinstance(cmap, str):\n",
    "                    cmap = plt.get_cmap(cmap)\n",
    "                cmap.set_bad('black')\n",
    "                img = axs[i, j].imshow(data*mask_3D[mask_index], cmap=cmap, vmin=vmin[j], vmax=vmax[j])\n",
    "\n",
    "            elif j == 4:\n",
    "                data = (curr_data[j, index, :, :]*scale_factor_nikita[j])\n",
    "                cmap = cbar_list[j]\n",
    "                if isinstance(cmap, str):\n",
    "                    cmap = plt.get_cmap(cmap)\n",
    "                cmap.set_bad('black')\n",
    "                img = axs[i, j].imshow(data, cmap=cmap, vmin=vmin[j], vmax=vmax[j])\n",
    "            elif j == 5:\n",
    "                data = curr_data[j, index, :, :]*scale_factor_nikita[j]\n",
    "                cmap = cbar_list[j]\n",
    "                if isinstance(cmap, str):\n",
    "                    cmap = plt.get_cmap(cmap)\n",
    "                cmap.set_bad('black')\n",
    "                img = axs[i, j].imshow(data, cmap=cmap, vmin=vmin[j], vmax=vmax[j])\n",
    "            else:\n",
    "                img = axs[i, j].imshow(curr_data[j, index, :,:]*scale_factor_nikita[j], cmap=cbar_list[j], vmin=vmin[j], vmax=vmax[j])\n",
    "\n",
    "\n",
    "\n",
    "        # Handle axis appearance\n",
    "        if j == 0:\n",
    "            # Keep ylabel visible but remove ticks and spines\n",
    "            axs[i, j].set_xticks([])\n",
    "            axs[i, j].set_yticks([])\n",
    "            for spine in axs[i, j].spines.values():\n",
    "                spine.set_visible(False)\n",
    "        else:\n",
    "            axs[i, j].axis('off')\n",
    "\n",
    "# Set row titles AFTER the main loop to avoid conflicts\n",
    "# Set row titles AFTER the main loop to avoid conflicts\n",
    "for i in range(8):\n",
    "    axs[i, 0].set_ylabel(row_titles[i], fontsize=20, color='white', rotation=0, labelpad=50, va='center')\n",
    "\n",
    "\n",
    "# Create colorbars ONCE, outside all loops\n",
    "for j in range(6):\n",
    "    # Get the position of the bottom subplot in each column\n",
    "    bottom_ax_pos = axs[-1, j].get_position()  # Last row (index -1)\n",
    "\n",
    "    cax = fig.add_axes([\n",
    "        bottom_ax_pos.x0,  # Same left position as subplot\n",
    "        bottom_ax_pos.y0 - 0.06,  # Below the subplot with spacing\n",
    "        bottom_ax_pos.width+0.01,  # Same width as subplot\n",
    "        0.02  # Height of colorbar\n",
    "    ])\n",
    "\n",
    "    cax.set_facecolor('black')\n",
    "    sm = cm.ScalarMappable(cmap=cbar_list[j], norm=plt.Normalize(vmin=vmin[j], vmax=vmax[j]))\n",
    "    sm.set_array([])\n",
    "    cbar = plt.colorbar(sm, cax=cax, orientation='horizontal', ticks=np.linspace(vmin[j], vmax[j], 5))\n",
    "    cbar.ax.tick_params(colors='white')\n",
    "    cbar.outline.set_edgecolor('white')\n",
    "\n",
    "#save image:\n",
    "save_path = os.path.join(config['save_path'], f\"phantom_method_comparison.png\")\n",
    "plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor=fig.get_facecolor())\n",
    "plt.show()"
   ],
   "id": "b1bb2c1f0cadef6a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# ICC calculation",
   "id": "b7c52dcad811dec6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def slicewise_icc(map1, map2, icctype='ICC2'):\n",
    "    \"\"\" ICC3.1 measures \"consistency\" while ICC2.1 measures \"absolute agreement\".\n",
    "    \"\"\"\n",
    "    import pingouin as pg\n",
    "\n",
    "    # Flatten the arrays\n",
    "    map1 = map1.flatten()\n",
    "    map2 = map2.flatten()\n",
    "\n",
    "    # Create mask for valid (non-NaN) values in BOTH arrays\n",
    "    valid_mask = ~np.isnan(map1) & ~np.isnan(map2)\n",
    "\n",
    "    # Check if we have enough valid data points\n",
    "    if np.sum(valid_mask) < 3:  # Need at least 3 points for ICC\n",
    "        return np.nan\n",
    "\n",
    "    # Extract only valid values\n",
    "    slice1 = map1[valid_mask]\n",
    "    slice2 = map2[valid_mask]\n",
    "\n",
    "    # Create DataFrame for ICC calculation\n",
    "    data = pd.DataFrame({\n",
    "        'targets': np.repeat(np.arange(len(slice1)), 2),\n",
    "        'raters': np.tile(['slice1', 'slice2'], len(slice1)),\n",
    "        'ratings': np.concatenate([slice1, slice2])\n",
    "    })\n",
    "\n",
    "    try:\n",
    "        # Compute the ICC\n",
    "        icc = pg.intraclass_corr(data=data, targets='targets', raters='raters',\n",
    "                                ratings='ratings', nan_policy='omit')\n",
    "\n",
    "        # Filter for correct type and store the result\n",
    "        icc_x = icc[icc['Type'] == icctype]\n",
    "        if len(icc_x) > 0:\n",
    "            icc_result = icc_x['ICC'].values[0]\n",
    "        else:\n",
    "            icc_result = np.nan\n",
    "    except:\n",
    "        icc_result = np.nan\n",
    "\n",
    "    return icc_result"
   ],
   "id": "866aecbe58089eca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "\n",
    "# Set up the methods and their data\n",
    "methods = {\n",
    "    'GT vs TBMF': (gt, tbmf_selective, 6),\n",
    "    'GT vs DOT_6': (gt, y_nikita_6_masked, 6),\n",
    "    'GT vs DOT_30': (gt, y_nikita_30_masked, 6),\n",
    "    'GT vs NBMF_6': (gt[:2,:,:,:], y_alex_nbmf_6_masked, 2),\n",
    "    'GT vs NBMF_30': (gt[:2,:,:,:], y_alex_nbmf_30_masked, 2),\n",
    "    'GT vs VBMF_6': (gt[:2,:,:,:], y_alex_vbmf_6_masked, 2),\n",
    "    'GT vs VBMF_30': (gt[:2,:,:,:], y_alex_vbmf_30_masked, 2)\n",
    "}\n",
    "\n",
    "# Parameter names\n",
    "param_names = [\n",
    "    r\"$K_{ssw}$ (S$^{-1}$)\",\n",
    "    r\"$f_s$ (%)\",\n",
    "    r\"$B_0$ (ppm)\",\n",
    "    r\"$B_1$ (rel.)\",\n",
    "    r\"$T_1$ (ms)\",\n",
    "    r\"$T_2$ (ms)\"\n",
    "]\n",
    "\n",
    "# Create figure\n",
    "fig, axes = plt.subplots(7, 6, figsize=(24, 28))\n",
    "fig.suptitle('Statistical Analysis: ICC and Pearson Correlation vs Ground Truth',\n",
    "             fontsize=16, fontweight='bold')\n",
    "\n",
    "# Scale factors\n",
    "scale_factor_alex = [1, 110e3/3]\n",
    "scale_factor_nikita = [1, 110e3/3, 1, 1, 1000, 1000]\n",
    "\n",
    "# Axis limits for each parameter [min, max]\n",
    "axis_limits = {\n",
    "    0: [0, 1400],      # K_ssw: 0-100\n",
    "    1: [0, 120],    # f_s: 0-27.27\n",
    "    2: [-0.6, 0.6],   # B_0: keep current range\n",
    "    3: [0.7, 1.3],      # B_1: keep current range\n",
    "    4: [2200, 3000],     # T_1: 0-3000\n",
    "    5: [400, 1000]       # T_2: 0-150\n",
    "}\n",
    "\n",
    "results_summary = []\n",
    "\n",
    "# Process each method\n",
    "for method_idx, (method_name, (data1, data2, n_params)) in enumerate(methods.items()):\n",
    "    print(f\"\\nProcessing {method_name}...\")\n",
    "\n",
    "    # Process each parameter\n",
    "    for param_idx in range(6):\n",
    "        ax = axes[method_idx, param_idx]\n",
    "\n",
    "        if param_idx < n_params:\n",
    "            # Skip B_1 for Nikita methods (rows 1,2)\n",
    "            if (method_idx == 1 or method_idx == 2) and param_idx == 3:\n",
    "\n",
    "                continue\n",
    "\n",
    "            # Extract parameter data\n",
    "            param1 = data1[param_idx].copy()\n",
    "            param2 = data2[param_idx].copy()\n",
    "\n",
    "            # Apply scaling to param1 (Ground Truth) - should be CONSISTENT across all methods\n",
    "\n",
    "\n",
    "            # Apply scaling to param2 (comparison methods) - should be METHOD-SPECIFIC\n",
    "            if method_idx == 1 or method_idx == 2:  # Nikita methods (DOT)\n",
    "                if param_idx < len(scale_factor_nikita):\n",
    "                    param2 = param2 * scale_factor_nikita[param_idx]\n",
    "            elif method_idx >= 3:  # Alex methods (NBMF/VBMF)\n",
    "                if param_idx < len(scale_factor_alex):\n",
    "                    param2 = param2 * scale_factor_alex[param_idx]\n",
    "\n",
    "\n",
    "\n",
    "            # Data validation and clipping\n",
    "            if param_idx == 0:  # K_ssw should be 0-100\n",
    "                param1 = np.clip(param1, 0, 1400)\n",
    "                param2 = np.clip(param2, 0, 1400)\n",
    "            elif param_idx == 1:  # f_s should be 0-27.27\n",
    "                param1 = np.clip(param1, 0, 120)\n",
    "                param2 = np.clip(param2, 0, 120)\n",
    "            elif param_idx == 4:  # T_1 should be 0-3000\n",
    "                param1 = np.clip(param1, 2200, 3400)\n",
    "                param2 = np.clip(param2, 2200, 3400)\n",
    "            elif param_idx == 5:  # T_2 should be 0-150\n",
    "                param1 = np.clip(param1, 400, 1000)\n",
    "                param2 = np.clip(param2, 400, 1000)\n",
    "\n",
    "            # Right after the scaling section, add:\n",
    "            print(f\"\\n{method_name}, Parameter {param_idx}:\")\n",
    "            print(f\"  param1 range: [{np.nanmin(param1):.3f}, {np.nanmax(param1):.3f}]\")\n",
    "            print(f\"  param2 range: [{np.nanmin(param2):.3f}, {np.nanmax(param2):.3f}]\")\n",
    "            print(f\"  axis limits: {axis_limits[param_idx]}\")\n",
    "            print(f\"  Valid points after scaling: {np.sum(~np.isnan(param1) & ~np.isnan(param2))}\")\n",
    "\n",
    "            # Calculate ICC using your original function\n",
    "            try:\n",
    "                icc_value = slicewise_icc(param1, param2, icctype='ICC2')\n",
    "                print(f\"ICC for {method_name}, {param_names[param_idx]}: {icc_value:.3f}\")\n",
    "            except:\n",
    "                icc_value = np.nan\n",
    "\n",
    "            # Calculate Pearson correlation\n",
    "            mask = ~np.isnan(param1) & ~np.isnan(param2)\n",
    "            param1_clean = param1[mask]\n",
    "            param2_clean = param2[mask]\n",
    "\n",
    "            try:\n",
    "                if len(param1_clean) > 10:\n",
    "                    pearson_r, pearson_p = stats.pearsonr(param1_clean, param2_clean)\n",
    "                    print(f\"Pearson r for {method_name}, {param_names[param_idx]}: {pearson_r:.3f}, p={pearson_p:.3e}\")\n",
    "\n",
    "                    # Create scatter plot\n",
    "                    ax.scatter(param1_clean, param2_clean, alpha=0.6, s=1, color='steelblue')\n",
    "\n",
    "                    # Set axis limits\n",
    "                    ax.set_xlim(axis_limits[param_idx])\n",
    "                    ax.set_ylim(axis_limits[param_idx])\n",
    "\n",
    "                    # Add identity line within axis limits\n",
    "                    lims = axis_limits[param_idx]\n",
    "                    ax.plot(lims, lims, 'r--', alpha=0.8, linewidth=1)\n",
    "\n",
    "                    # Add regression line\n",
    "                    if not (np.isnan(pearson_r) or pearson_r == 0):\n",
    "                        slope, intercept = np.polyfit(param1_clean, param2_clean, 1)\n",
    "                        x_reg = np.array(lims)\n",
    "                        y_reg = slope * x_reg + intercept\n",
    "                        # Clip regression line to axis limits\n",
    "                        y_reg = np.clip(y_reg, lims[0], lims[1])\n",
    "                        ax.plot(x_reg, y_reg, 'orange', linewidth=1.5)\n",
    "\n",
    "                    # Set labels and title\n",
    "                    ax.set_xlabel('Ground Truth' if method_idx == len(methods)-1 else '')\n",
    "                    ax.set_ylabel(method_name.split(' vs ')[1] if param_idx == 0 else '')\n",
    "\n",
    "                    # Add statistics text\n",
    "                    stats_text = f'r = {pearson_r:.3f}\\n'\n",
    "                    if pearson_p < 0.001:\n",
    "                        stats_text += 'p < 0.001\\n'\n",
    "                    else:\n",
    "                        stats_text += f'p = {pearson_p:.3f}\\n'\n",
    "                    stats_text += f'ICC = {icc_value:.3f}'\n",
    "\n",
    "                    ax.text(0.05, 0.95, stats_text, transform=ax.transAxes,\n",
    "                           fontsize=8, verticalalignment='top',\n",
    "                           bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "                    # Store checkpoints\n",
    "                    results_summary.append({\n",
    "                        'Method': method_name,\n",
    "                        'Parameter': param_names[param_idx],\n",
    "                        'Pearson_r': pearson_r,\n",
    "                        'Pearson_p': pearson_p,\n",
    "                        'ICC': icc_value,\n",
    "                        'N_points': len(param1_clean)\n",
    "                    })\n",
    "                else:\n",
    "                    ax.text(0.5, 0.5, 'Insufficient\\ndata', transform=ax.transAxes,\n",
    "                           ha='center', va='center', fontsize=10)\n",
    "                    ax.set_xticks([])\n",
    "                    ax.set_yticks([])\n",
    "\n",
    "            except Exception as e:\n",
    "                ax.text(0.5, 0.5, 'Error in\\ncalculation', transform=ax.transAxes,\n",
    "                       ha='center', va='center', fontsize=10)\n",
    "                ax.set_xticks([])\n",
    "                ax.set_yticks([])\n",
    "                print(f\"Error in {method_name}, {param_names[param_idx]}: {e}\")\n",
    "\n",
    "        else:\n",
    "            # Empty subplot for parameters not available in this method\n",
    "            ax.axis('off')\n",
    "\n",
    "        # Add parameter title on top row\n",
    "        if method_idx == 0:\n",
    "            ax.set_title(param_names[param_idx], fontweight='bold')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.95)\n",
    "plt.savefig(\"/home/sahar/Models/Dinor_revision/new_phantom/dinor_train/code_addition/phanton_comp/Method_ICC_single.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Create summary table with error handling\n",
    "results_df = pd.DataFrame(results_summary)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY TABLE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if not results_df.empty:\n",
    "    # Pivot table for better visualization\n",
    "    summary_table = results_df.pivot_table(\n",
    "        index='Method',\n",
    "        columns='Parameter',\n",
    "        values=['Pearson_r', 'ICC'],\n",
    "        aggfunc='first'\n",
    "    )\n",
    "\n",
    "    print(\"\\nPearson Correlation Coefficients (r):\")\n",
    "    print(\"-\" * 50)\n",
    "    pearson_table = summary_table['Pearson_r'].round(3)\n",
    "    print(pearson_table.to_string())\n",
    "\n",
    "    print(\"\\nIntraclass Correlation Coefficients (ICC):\")\n",
    "    print(\"-\" * 50)\n",
    "    if 'ICC' in summary_table.columns:\n",
    "        icc_table = summary_table['ICC'].round(3)\n",
    "        print(icc_table.to_string())\n",
    "    else:\n",
    "        icc_manual = results_df.pivot_table(\n",
    "            index='Method',\n",
    "            columns='Parameter',\n",
    "            values='ICC',\n",
    "            aggfunc='first'\n",
    "        ).round(3)\n",
    "        print(icc_manual.to_string())\n",
    "\n",
    "    print(\"\\nPearson p-values:\")\n",
    "    print(\"-\" * 20)\n",
    "    p_table = results_df.pivot_table(\n",
    "        index='Method',\n",
    "        columns='Parameter',\n",
    "        values='Pearson_p',\n",
    "        aggfunc='first'\n",
    "    ).round(4)\n",
    "    print(p_table.to_string())\n",
    "\n",
    "    # Save checkpoints to CSV\n",
    "    results_df.to_csv('/home/sahar/Models/Dinor_revision/new_phantom/dinor_train/code_addition/phanton_comp/correlation_icc_results.csv', index=False)\n",
    "    print(f\"\\nDetailed checkpoints saved to 'correlation_icc_results.csv'\")\n",
    "else:\n",
    "    print(\"No valid checkpoints to display!\")\n"
   ],
   "id": "252d60dda56e1e96",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# PSNR NRMSE and SSIM",
   "id": "b92e3b8ba737a1ca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchmetrics.image import StructuralSimilarityIndexMeasure\n",
    "from torchmetrics.image import PeakSignalNoiseRatio\n",
    "from torch.nn.functional import mse_loss\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def apply_scaling(data, method, param_idx):\n",
    "    \"\"\"Apply scaling based on method type and parameter index\"\"\"\n",
    "    if method == \"gt\":\n",
    "        # No scaling for ground truth - keep original values\n",
    "        return data\n",
    "    elif method == \"tbmf\":\n",
    "        # No scaling for TBMF - keep original values\n",
    "        return data\n",
    "    elif method == \"nikita\":\n",
    "        # Scale factors for Nikita methods (DOT)\n",
    "        scale_factor = [1, 110e3/3, 1, 1, 1000, 1000]\n",
    "        if param_idx < len(scale_factor):\n",
    "            return data * scale_factor[param_idx]\n",
    "        else:\n",
    "            return data\n",
    "    else:  # alex methods (NBMF, VBMF)\n",
    "        # Scale factors for Alex methods\n",
    "        scale_factor = [1, 110e3/3]\n",
    "        if param_idx < len(scale_factor):\n",
    "            return data * scale_factor[param_idx]\n",
    "        else:\n",
    "            return data\n",
    "\n",
    "def get_method_type(method_name):\n",
    "    \"\"\"Determine method type for scaling\"\"\"\n",
    "    if 'TBMF' in method_name.upper():\n",
    "        return 'tbmf'\n",
    "    elif 'DOT' in method_name.upper():\n",
    "        return 'nikita'\n",
    "    else:  # NBMF, VBMF\n",
    "        return 'alex'\n",
    "\n",
    "def calc_metrics_pytorch_scaled(y_pred, y_true, method_name, param_idx, param_name=\"\"):\n",
    "    \"\"\"\n",
    "    Calculate metrics using PyTorch torchmetrics with proper scaling\n",
    "    \"\"\"\n",
    "    # Apply scaling based on method type\n",
    "    gt_method = 'gt'\n",
    "    pred_method = get_method_type(method_name)\n",
    "\n",
    "    # Scale both GT and predicted data\n",
    "    y_true_scaled = apply_scaling(y_true.copy(), gt_method, param_idx)\n",
    "    y_pred_scaled = apply_scaling(y_pred.copy(), pred_method, param_idx)\n",
    "\n",
    "    # Get valid pixels\n",
    "    valid_mask = ~np.isnan(y_pred_scaled) & ~np.isnan(y_true_scaled)\n",
    "\n",
    "    if np.sum(valid_mask) < 100:  # Need sufficient valid pixels\n",
    "        return {'psnr': np.nan, 'nrmse': np.nan, 'ssim': np.nan}\n",
    "\n",
    "    # Extract valid values\n",
    "    pred_valid = y_pred_scaled[valid_mask]\n",
    "    true_valid = y_true_scaled[valid_mask]\n",
    "\n",
    "    # Normalize both to 0-1 range based on ground truth range\n",
    "    true_min, true_max = np.min(true_valid), np.max(true_valid)\n",
    "\n",
    "    if true_max <= true_min:\n",
    "        return {'psnr': np.inf, 'nrmse': 0.0, 'ssim': 1.0}  # Perfect match\n",
    "\n",
    "    # Create full volumes with NaN replaced by mean\n",
    "    pred_volume = y_pred_scaled.copy()\n",
    "    true_volume = y_true_scaled.copy()\n",
    "    pred_volume[~valid_mask] = np.mean(pred_valid)\n",
    "    true_volume[~valid_mask] = np.mean(true_valid)\n",
    "\n",
    "    # Normalize to 0-1 range\n",
    "    true_volume_norm = (true_volume - true_min) / (true_max - true_min)\n",
    "    pred_volume_norm = np.clip((pred_volume - true_min) / (true_max - true_min), 0, 1)\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    # For torchmetrics, we need shape (N, C, H, W) where N=batch, C=channels\n",
    "    # We'll treat each depth slice as a separate sample in the batch\n",
    "    depth = pred_volume_norm.shape[2]\n",
    "\n",
    "    # Reshape: (H, W, D) -> (D, 1, H, W) for batch processing\n",
    "    pred_tensor = torch.from_numpy(pred_volume_norm).float().permute(2, 0, 1).unsqueeze(1)\n",
    "    true_tensor = torch.from_numpy(true_volume_norm).float().permute(2, 0, 1).unsqueeze(1)\n",
    "\n",
    "    # Initialize metrics\n",
    "    psnr_metric = PeakSignalNoiseRatio(data_range=1.0)\n",
    "    ssim_metric = StructuralSimilarityIndexMeasure(data_range=1.0)\n",
    "\n",
    "    # Calculate PSNR (can be done on entire batch)\n",
    "    try:\n",
    "        psnr_val = psnr_metric(pred_tensor, true_tensor).item()\n",
    "    except:\n",
    "        psnr_val = np.nan\n",
    "\n",
    "    # Calculate SSIM (can be done on entire batch)\n",
    "    try:\n",
    "        ssim_val = ssim_metric(pred_tensor, true_tensor).item()\n",
    "    except:\n",
    "        ssim_val = np.nan\n",
    "\n",
    "    # Calculate NRMSE using MSE loss\n",
    "    try:\n",
    "        mse_val = mse_loss(pred_tensor, true_tensor).item()\n",
    "        nrmse_val = np.sqrt(mse_val)  # Already normalized since data is 0-1\n",
    "    except:\n",
    "        nrmse_val = np.nan\n",
    "\n",
    "    return {\n",
    "        'psnr': psnr_val,\n",
    "        'nrmse': nrmse_val,\n",
    "        'ssim': ssim_val\n",
    "    }\n",
    "\n",
    "def calculate_metrics_pytorch_scaled_phantom(gt, tbmf_selective, y_nikita_6_masked, y_nikita_30_masked,\n",
    "                                           y_alex_nbmf_6_masked, y_alex_nbmf_30_masked,\n",
    "                                           y_alex_vbmf_6_masked, y_alex_vbmf_30_masked,\n",
    "                                           save_path=\"/home/sahar/Models/Dinor_revision/new_phantom/dinor_train/code_addition/phanton_comp/\"):\n",
    "    \"\"\"\n",
    "    Calculate PSNR, NRMSE, and SSIM metrics using PyTorch torchmetrics with proper scaling\n",
    "    for your phantom data\n",
    "    \"\"\"\n",
    "    # Define methods to compare using your data variables\n",
    "    methods_to_compare = {\n",
    "        'TBMF': {\n",
    "            'data': (gt, tbmf_selective, 6),\n",
    "            'n_params': 6\n",
    "        },\n",
    "        'DOT_6': {\n",
    "            'data': (gt, y_nikita_6_masked, 6),\n",
    "            'n_params': 6\n",
    "        },\n",
    "        'DOT_30': {\n",
    "            'data': (gt, y_nikita_30_masked, 6),\n",
    "            'n_params': 6\n",
    "        },\n",
    "        'NBMF_6': {\n",
    "            'data': (gt[:2], y_alex_nbmf_6_masked, 2),\n",
    "            'n_params': 2\n",
    "        },\n",
    "        'NBMF_30': {\n",
    "            'data': (gt[:2], y_alex_nbmf_30_masked, 2),\n",
    "            'n_params': 2\n",
    "        },\n",
    "        'VBMF_6': {\n",
    "            'data': (gt[:2], y_alex_vbmf_6_masked, 2),\n",
    "            'n_params': 2\n",
    "        },\n",
    "        'VBMF_30': {\n",
    "            'data': (gt[:2], y_alex_vbmf_30_masked, 2),\n",
    "            'n_params': 2\n",
    "        }\n",
    "    }\n",
    "\n",
    "    param_names = ['ksw', 'fs', 'b0', 'b1', 't1', 't2']\n",
    "    all_results = []  # Store all individual checkpoints for comprehensive CSV\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    print(\"\\nCalculating metrics using PyTorch torchmetrics with proper scaling...\")\n",
    "    print(\"=\" * 75)\n",
    "\n",
    "    for method_name, method_info in methods_to_compare.items():\n",
    "        print(f\"\\nProcessing {method_name}...\")\n",
    "        results[method_name] = {}\n",
    "\n",
    "        gt_data, pred_data, n_params = method_info['data']\n",
    "        n_params = method_info['n_params']\n",
    "\n",
    "        print(f\"  GT shape: {gt_data.shape}, Pred shape: {pred_data.shape}\")\n",
    "\n",
    "        vol_results = {\n",
    "            'psnr': [],\n",
    "            'nrmse': [],\n",
    "            'ssim': []\n",
    "        }\n",
    "\n",
    "        param_names_subset = param_names[:n_params]\n",
    "\n",
    "        for param_idx in range(n_params):\n",
    "            # Skip B1 for DOT methods (index 3)\n",
    "            if method_name.startswith('DOT') and param_idx == 3:\n",
    "                vol_results['psnr'].append(np.nan)\n",
    "                vol_results['nrmse'].append(np.nan)\n",
    "                vol_results['ssim'].append(np.nan)\n",
    "                print(f\"    {param_names_subset[param_idx]}: SKIPPED (B1 not available for DOT)\")\n",
    "\n",
    "                # Still add to all_results for completeness\n",
    "                all_results.append({\n",
    "                    'Method': method_name,\n",
    "                    'Parameter': param_names_subset[param_idx],\n",
    "                    'Parameter_Index': param_idx,\n",
    "                    'PSNR': np.nan,\n",
    "                    'NRMSE': np.nan,\n",
    "                    'SSIM': np.nan,\n",
    "                    'Status': 'Skipped (B1 not available)'\n",
    "                })\n",
    "                continue\n",
    "\n",
    "            param_name = param_names_subset[param_idx]\n",
    "            gt_param = gt_data[param_idx]  # Shape: (depth, height, width)\n",
    "            pred_param = pred_data[param_idx]  # Shape: (depth, height, width)\n",
    "\n",
    "            # Calculate metrics using PyTorch with scaling\n",
    "            metrics = calc_metrics_pytorch_scaled(pred_param, gt_param, method_name, param_idx, param_name)\n",
    "\n",
    "            vol_results['psnr'].append(metrics['psnr'])\n",
    "            vol_results['nrmse'].append(metrics['nrmse'])\n",
    "            vol_results['ssim'].append(metrics['ssim'])\n",
    "\n",
    "            # Handle infinite PSNR for display\n",
    "            psnr_display = \"inf\" if np.isinf(metrics['psnr']) else f\"{metrics['psnr']:.3f}\"\n",
    "            print(f\"    {param_name}: PSNR={psnr_display}, \"\n",
    "                  f\"NRMSE={metrics['nrmse']:.4f}, SSIM={metrics['ssim']:.4f}\")\n",
    "\n",
    "            # Add to comprehensive checkpoints\n",
    "            all_results.append({\n",
    "                'Method': method_name,\n",
    "                'Parameter': param_name,\n",
    "                'Parameter_Index': param_idx,\n",
    "                'PSNR': metrics['psnr'] if not np.isinf(metrics['psnr']) else 'inf',\n",
    "                'NRMSE': metrics['nrmse'],\n",
    "                'SSIM': metrics['ssim'],\n",
    "                'Status': 'Calculated'\n",
    "            })\n",
    "\n",
    "        # Calculate averages (excluding inf and nan values)\n",
    "        psnr_finite = [x for x in vol_results['psnr'] if np.isfinite(x)]\n",
    "        nrmse_finite = [x for x in vol_results['nrmse'] if np.isfinite(x)]\n",
    "        ssim_finite = [x for x in vol_results['ssim'] if np.isfinite(x)]\n",
    "\n",
    "        avg_psnr = np.mean(psnr_finite) if psnr_finite else np.nan\n",
    "        avg_nrmse = np.mean(nrmse_finite) if nrmse_finite else np.nan\n",
    "        avg_ssim = np.mean(ssim_finite) if ssim_finite else np.nan\n",
    "\n",
    "        print(f\"    Average: PSNR={avg_psnr:.3f}, NRMSE={avg_nrmse:.4f}, SSIM={avg_ssim:.4f}\")\n",
    "\n",
    "        results[method_name] = vol_results\n",
    "\n",
    "    return results, all_results, save_path\n",
    "\n",
    "def create_summary_table_pytorch_phantom(results):\n",
    "    \"\"\"Create summary table for PyTorch metrics checkpoints\"\"\"\n",
    "    summary_data = []\n",
    "\n",
    "    for method_name, method_results in results.items():\n",
    "        # Collect finite values only\n",
    "        psnr_finite = [x for x in method_results['psnr'] if np.isfinite(x)]\n",
    "        nrmse_finite = [x for x in method_results['nrmse'] if np.isfinite(x)]\n",
    "        ssim_finite = [x for x in method_results['ssim'] if np.isfinite(x)]\n",
    "\n",
    "        summary_data.append({\n",
    "            'Method': method_name,\n",
    "            'PSNR_mean': np.mean(psnr_finite) if psnr_finite else np.nan,\n",
    "            'PSNR_std': np.std(psnr_finite) if psnr_finite else np.nan,\n",
    "            'NRMSE_mean': np.mean(nrmse_finite) if nrmse_finite else np.nan,\n",
    "            'NRMSE_std': np.std(nrmse_finite) if nrmse_finite else np.nan,\n",
    "            'SSIM_mean': np.mean(ssim_finite) if ssim_finite else np.nan,\n",
    "            'SSIM_std': np.std(ssim_finite) if ssim_finite else np.nan,\n",
    "            'N_valid': len(psnr_finite)\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(summary_data)\n",
    "\n",
    "# Main execution function\n",
    "def run_phantom_metrics_analysis():\n",
    "    \"\"\"\n",
    "    Main function to run the complete metrics analysis on your phantom data\n",
    "    \"\"\"\n",
    "    # Make sure your data variables are available in the global scope\n",
    "    # You should have: gt, tbmf_selective, y_nikita_6_masked, y_nikita_30_masked,\n",
    "    # y_alex_nbmf_6_masked, y_alex_nbmf_30_masked, y_alex_vbmf_6_masked, y_alex_vbmf_30_masked\n",
    "\n",
    "    # Run the analysis with proper scaling\n",
    "    results_scaled, all_results_data, save_path = calculate_metrics_pytorch_scaled_phantom(\n",
    "        gt, tbmf_selective, y_nikita_6_masked, y_nikita_30_masked,\n",
    "        y_alex_nbmf_6_masked, y_alex_nbmf_30_masked,\n",
    "        y_alex_vbmf_6_masked, y_alex_vbmf_30_masked\n",
    "    )\n",
    "\n",
    "    # Create summary\n",
    "    summary_df_scaled = create_summary_table_pytorch_phantom(results_scaled)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 85)\n",
    "    print(\"PHANTOM SCALED METRICS SUMMARY (PyTorch torchmetrics)\")\n",
    "    print(\"=\" * 85)\n",
    "\n",
    "    # Format and display checkpoints table\n",
    "    formatted_results_scaled = []\n",
    "    for _, row in summary_df_scaled.iterrows():\n",
    "        formatted_results_scaled.append({\n",
    "            'Method': row['Method'],\n",
    "            'PSNR': f\"{row['PSNR_mean']:.3f}  {row['PSNR_std']:.3f}\",\n",
    "            'NRMSE': f\"{row['NRMSE_mean']:.4f}  {row['NRMSE_std']:.4f}\",\n",
    "            'SSIM': f\"{row['SSIM_mean']:.4f}  {row['SSIM_std']:.4f}\",\n",
    "            'N': int(row['N_valid'])\n",
    "        })\n",
    "\n",
    "    formatted_df_scaled = pd.DataFrame(formatted_results_scaled)\n",
    "    print(formatted_df_scaled.to_string(index=False))\n",
    "\n",
    "    # Save comprehensive checkpoints to single CSV\n",
    "    all_results_df = pd.DataFrame(all_results_data)\n",
    "\n",
    "    # Save to CSV\n",
    "    csv_filename = os.path.join(save_path, 'phantom_comprehensive_metrics.csv')\n",
    "    all_results_df.to_csv(csv_filename, index=False)\n",
    "\n",
    "    # Also save summary\n",
    "    summary_csv_filename = os.path.join(save_path, 'phantom_summary_metrics.csv')\n",
    "    summary_df_scaled.to_csv(summary_csv_filename, index=False)\n",
    "\n",
    "    print(f\"\\nResults saved:\")\n",
    "    print(f\"- Comprehensive data: '{csv_filename}'\")\n",
    "    print(f\"- Summary data: '{summary_csv_filename}'\")\n",
    "\n",
    "    # Display first few rows of comprehensive data\n",
    "    print(f\"\\nFirst 10 rows of comprehensive data:\")\n",
    "    print(all_results_df.head(10).to_string(index=False))\n",
    "\n",
    "    print(f\"\\nTotal number of metric calculations: {len(all_results_df)}\")\n",
    "    print(f\"Successful calculations: {len(all_results_df[all_results_df['Status'] == 'Calculated'])}\")\n",
    "    print(f\"Skipped calculations: {len(all_results_df[all_results_df['Status'] != 'Calculated'])}\")\n",
    "\n",
    "    return results_scaled, all_results_df, summary_df_scaled\n",
    "\n",
    "# To run the analysis, simply call:\n",
    "results_scaled, all_results_df, summary_df_scaled = run_phantom_metrics_analysis()"
   ],
   "id": "c5353dc350c8ec0f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# APE and boxplots",
   "id": "c01c46a359b0257"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "def calculate_ape(y_pred, y_true, method_name, param_idx):\n",
    "    \"\"\"\n",
    "    Calculate Absolute Percentage Error (APE) for all valid pixels\n",
    "    APE = |y_true - y_pred| / |y_true| * 100\n",
    "    \"\"\"\n",
    "    # Apply scaling based on method type\n",
    "    gt_method = 'gt'\n",
    "    pred_method = get_method_type(method_name)\n",
    "\n",
    "    # Scale both GT and predicted data\n",
    "    y_true_scaled = apply_scaling(y_true.copy(), gt_method, param_idx)\n",
    "    y_pred_scaled = apply_scaling(y_pred.copy(), pred_method, param_idx)\n",
    "\n",
    "    # Get valid pixels (non-NaN and non-zero denominators)\n",
    "    valid_mask = (~np.isnan(y_pred_scaled) &\n",
    "                  ~np.isnan(y_true_scaled) &\n",
    "                  (np.abs(y_true_scaled) > 1e-10))  # Avoid division by very small numbers\n",
    "\n",
    "    if np.sum(valid_mask) < 10:  # Need sufficient valid pixels\n",
    "        return np.array([])\n",
    "\n",
    "    # Extract valid values\n",
    "    pred_valid = y_pred_scaled[valid_mask]\n",
    "    true_valid = y_true_scaled[valid_mask]\n",
    "\n",
    "    # Calculate APE\n",
    "    ape = np.abs(true_valid - pred_valid) / np.abs(true_valid) * 100\n",
    "\n",
    "    # Remove outliers (APE > 500% might be unrealistic)\n",
    "    ape_filtered = ape[ape <= 500]\n",
    "\n",
    "    return ape_filtered\n",
    "\n",
    "def calculate_all_ape_phantom(gt, tbmf_selective, y_nikita_6_masked, y_nikita_30_masked,\n",
    "                             y_alex_nbmf_6_masked, y_alex_nbmf_30_masked,\n",
    "                             y_alex_vbmf_6_masked, y_alex_vbmf_30_masked):\n",
    "    \"\"\"\n",
    "    Calculate APE for all methods and parameters\n",
    "    \"\"\"\n",
    "    # Define methods to compare\n",
    "    methods_to_compare = {\n",
    "        'TBMF': {\n",
    "            'data': (gt, tbmf_selective, 6),\n",
    "            'n_params': 6\n",
    "        },\n",
    "        'DOT_6': {\n",
    "            'data': (gt, y_nikita_6_masked, 6),\n",
    "            'n_params': 6\n",
    "        },\n",
    "        'DOT_30': {\n",
    "            'data': (gt, y_nikita_30_masked, 6),\n",
    "            'n_params': 6\n",
    "        },\n",
    "        'NBMF_6': {\n",
    "            'data': (gt[:2], y_alex_nbmf_6_masked, 2),\n",
    "            'n_params': 2\n",
    "        },\n",
    "        'NBMF_30': {\n",
    "            'data': (gt[:2], y_alex_nbmf_30_masked, 2),\n",
    "            'n_params': 2\n",
    "        },\n",
    "        'VBMF_6': {\n",
    "            'data': (gt[:2], y_alex_vbmf_6_masked, 2),\n",
    "            'n_params': 2\n",
    "        },\n",
    "        'VBMF_30': {\n",
    "            'data': (gt[:2], y_alex_vbmf_30_masked, 2),\n",
    "            'n_params': 2\n",
    "        }\n",
    "    }\n",
    "\n",
    "    param_names = ['K_ssw', 'f_s', 'B_0', 'B_1', 'T_1', 'T_2']\n",
    "    param_units = ['(S)', '(%)', '(ppm)', '(rel.)', '(ms)', '(ms)']\n",
    "\n",
    "    ape_data = []\n",
    "    ape_results = {}\n",
    "\n",
    "    print(\"Calculating APE for all methods and parameters...\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    for method_name, method_info in methods_to_compare.items():\n",
    "        print(f\"\\nProcessing {method_name}...\")\n",
    "\n",
    "        gt_data, pred_data, n_params = method_info['data']\n",
    "        n_params = method_info['n_params']\n",
    "\n",
    "        ape_results[method_name] = {}\n",
    "\n",
    "        for param_idx in range(n_params):\n",
    "            # Skip B1 for DOT methods (index 3)\n",
    "            if method_name.startswith('DOT') and param_idx == 3:\n",
    "                print(f\"  {param_names[param_idx]}: SKIPPED (B1 not available for DOT)\")\n",
    "                ape_results[method_name][param_idx] = np.array([])\n",
    "                continue\n",
    "\n",
    "            param_name = param_names[param_idx]\n",
    "            gt_param = gt_data[param_idx]\n",
    "            pred_param = pred_data[param_idx]\n",
    "\n",
    "            # Calculate APE\n",
    "            ape_values = calculate_ape(pred_param, gt_param, method_name, param_idx)\n",
    "            ape_results[method_name][param_idx] = ape_values\n",
    "\n",
    "            if len(ape_values) > 0:\n",
    "                median_ape = np.median(ape_values)\n",
    "                q25_ape = np.percentile(ape_values, 25)\n",
    "                q75_ape = np.percentile(ape_values, 75)\n",
    "                mean_ape = np.mean(ape_values)\n",
    "\n",
    "                print(f\"  {param_name}: {len(ape_values)} pixels, \"\n",
    "                      f\"Median APE: {median_ape:.2f}%, \"\n",
    "                      f\"Mean APE: {mean_ape:.2f}%, \"\n",
    "                      f\"IQR: [{q25_ape:.2f}%, {q75_ape:.2f}%]\")\n",
    "\n",
    "                # Store data for plotting\n",
    "                for ape_val in ape_values:\n",
    "                    ape_data.append({\n",
    "                        'Method': method_name,\n",
    "                        'Parameter': param_name,\n",
    "                        'Parameter_Index': param_idx,\n",
    "                        'APE': ape_val\n",
    "                    })\n",
    "            else:\n",
    "                print(f\"  {param_name}: No valid data\")\n",
    "\n",
    "    return ape_results, pd.DataFrame(ape_data), param_names, param_units\n",
    "\n",
    "def create_ape_boxplots(ape_results, ape_df, param_names, param_units,\n",
    "                       save_path=\"/home/sahar/Models/Dinor_revision/new_phantom/dinor_train/code_addition/phanton_comp/\"):\n",
    "    \"\"\"\n",
    "    Create boxplots for APE values for each parameter across all methods\n",
    "    \"\"\"\n",
    "    # Define colors for each method\n",
    "    method_colors = {\n",
    "        'TBMF': '#1f77b4',      # Blue\n",
    "        'DOT_6': '#ff7f0e',     # Orange\n",
    "        'DOT_30': '#d62728',    # Red\n",
    "        'NBMF_6': '#2ca02c',    # Green\n",
    "        'NBMF_30': '#9467bd',   # Purple\n",
    "        'VBMF_6': '#8c564b',    # Brown\n",
    "        'VBMF_30': '#e377c2'    # Pink\n",
    "    }\n",
    "\n",
    "    # Create figure with subplots for each parameter\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    fig.suptitle('Absolute Percentage Error (APE) by Parameter and Method', fontsize=16, fontweight='bold')\n",
    "\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for param_idx in range(6):\n",
    "\n",
    "        ax = axes[param_idx]\n",
    "        if param_idx==3:\n",
    "            ax.axis(\"off\")\n",
    "            continue\n",
    "\n",
    "        # Filter data for current parameter\n",
    "        param_data = ape_df[ape_df['Parameter_Index'] == param_idx]\n",
    "\n",
    "        if param_data.empty:\n",
    "            ax.text(0.5, 0.5, f'No data for\\n{param_names[param_idx]}',\n",
    "                   transform=ax.transAxes, ha='center', va='center', fontsize=12)\n",
    "            ax.set_title(f'{param_names[param_idx]} {param_units[param_idx]}', fontweight='bold')\n",
    "            continue\n",
    "\n",
    "        # Create boxplot\n",
    "        methods_present = param_data['Method'].unique()\n",
    "        colors_for_plot = [method_colors[method] for method in methods_present]\n",
    "\n",
    "        bp = ax.boxplot([param_data[param_data['Method'] == method]['APE'].values\n",
    "                        for method in methods_present],\n",
    "                       tick_labels=methods_present,\n",
    "                       patch_artist=True,\n",
    "                       showfliers=False,  # Hide outliers for cleaner plot\n",
    "                       medianprops={'color': 'black', 'linewidth': 2})\n",
    "\n",
    "        # Color the boxes\n",
    "        for patch, color in zip(bp['boxes'], colors_for_plot):\n",
    "            patch.set_facecolor(color)\n",
    "            patch.set_alpha(0.7)\n",
    "\n",
    "        # Customize the plot\n",
    "        ax.set_title(f'{param_names[param_idx]} {param_units[param_idx]}', fontweight='bold')\n",
    "        ax.set_ylabel('APE (%)')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        # Rotate x-labels if needed\n",
    "        ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "        # Set reasonable y-axis limits (up to 95th percentile to avoid extreme outliers)\n",
    "        if len(param_data) > 0:\n",
    "            y_max = np.percentile(param_data['APE'], 95)\n",
    "            ax.set_ylim(0, y_max * 1.2)  # Cap at 100% for readability\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the plot\n",
    "    plot_filename = f\"{save_path}/ape_boxplots_by_parameter_with_IQR.png\"\n",
    "    plt.savefig(plot_filename, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"APE boxplots saved to: {plot_filename}\")\n",
    "\n",
    "def create_ape_summary_table(ape_df):\n",
    "    \"\"\"\n",
    "    Create a summary table with APE statistics\n",
    "    \"\"\"\n",
    "    summary_stats = []\n",
    "\n",
    "    for param_name in ape_df['Parameter'].unique():\n",
    "        param_data = ape_df[ape_df['Parameter'] == param_name]\n",
    "\n",
    "        for method in param_data['Method'].unique():\n",
    "            method_data = param_data[param_data['Method'] == method]['APE']\n",
    "\n",
    "            if len(method_data) > 0:\n",
    "                summary_stats.append({\n",
    "                    'Parameter': param_name,\n",
    "                    'Method': method,\n",
    "                    'Count': len(method_data),\n",
    "                    'Mean_APE': np.mean(method_data),\n",
    "                    'Median_APE': np.median(method_data),\n",
    "                    'Q25_APE': np.percentile(method_data, 25),\n",
    "                    'Q75_APE': np.percentile(method_data, 75),\n",
    "                    'Min_APE': np.min(method_data),\n",
    "                    'Max_APE': np.max(method_data),\n",
    "                    'Std_APE': np.std(method_data)\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(summary_stats)\n",
    "\n",
    "def create_method_comparison_boxplot(ape_df, save_path=\"/home/sahar/Models/Dinor_revision/new_phantom/dinor_train/code_addition/phanton_comp/\"):\n",
    "    \"\"\"\n",
    "    Create a single boxplot comparing all methods across all parameters\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Define colors for each method\n",
    "    method_colors = {\n",
    "        'TBMF': '#1f77b4',      # Blue\n",
    "        'DOT_6': '#ff7f0e',     # Orange\n",
    "        'DOT_30': '#d62728',    # Red\n",
    "        'NBMF_6': '#2ca02c',    # Green\n",
    "        'NBMF_30': '#9467bd',   # Purple\n",
    "        'VBMF_6': '#8c564b',    # Brown\n",
    "        'VBMF_30': '#e377c2'    # Pink\n",
    "    }\n",
    "\n",
    "    methods_present = ape_df['Method'].unique()\n",
    "    colors_for_plot = [method_colors[method] for method in methods_present]\n",
    "\n",
    "    bp = plt.boxplot([ape_df[ape_df['Method'] == method]['APE'].values\n",
    "                     for method in methods_present],\n",
    "                    tick_labels=methods_present,\n",
    "                    patch_artist=True,\n",
    "                    showfliers=False,\n",
    "                    medianprops={'color': 'black', 'linewidth': 2})\n",
    "\n",
    "    # Color the boxes\n",
    "    for patch, color in zip(bp['boxes'], colors_for_plot):\n",
    "        patch.set_facecolor(color)\n",
    "        patch.set_alpha(0.7)\n",
    "\n",
    "    plt.title('Overall APE Comparison Across All Methods and Parameters', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('APE (%)')\n",
    "    plt.xlabel('Method')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    # Set reasonable y-axis limits\n",
    "    y_max = np.percentile(ape_df['APE'], 95)\n",
    "    plt.ylim(0, y_max * 1.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the plot\n",
    "    plot_filename = f\"{save_path}/ape_boxplots_overall_comparison_with_IQR.png\"\n",
    "    plt.savefig(plot_filename, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Overall APE comparison saved to: {plot_filename}\")\n",
    "\n",
    "def run_ape_analysis():\n",
    "    \"\"\"\n",
    "    Main function to run complete APE analysis\n",
    "    \"\"\"\n",
    "    # Calculate APE for all methods and parameters\n",
    "    ape_results, ape_df, param_names, param_units = calculate_all_ape_phantom(\n",
    "        gt, tbmf_selective, y_nikita_6_masked, y_nikita_30_masked,\n",
    "        y_alex_nbmf_6_masked, y_alex_nbmf_30_masked,\n",
    "        y_alex_vbmf_6_masked, y_alex_vbmf_30_masked\n",
    "    )\n",
    "\n",
    "    # Create boxplots by parameter\n",
    "    create_ape_boxplots(ape_results, ape_df, param_names, param_units)\n",
    "\n",
    "    # Create overall method comparison\n",
    "    create_method_comparison_boxplot(ape_df)\n",
    "\n",
    "    # Create summary table\n",
    "    summary_table = create_ape_summary_table(ape_df)\n",
    "\n",
    "    # Display summary statistics\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"APE SUMMARY STATISTICS\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Show summary for each parameter\n",
    "    for param in param_names[:6]:\n",
    "        param_summary = summary_table[summary_table['Parameter'] == param]\n",
    "        if not param_summary.empty:\n",
    "            print(f\"\\n{param}:\")\n",
    "            print(\"-\" * 40)\n",
    "            for _, row in param_summary.iterrows():\n",
    "                print(f\"  {row['Method']:10}: \"\n",
    "                      f\"Median={row['Median_APE']:6.2f}%, \"\n",
    "                      f\"Mean={row['Mean_APE']:6.2f}%, \"\n",
    "                      f\"IQR=[{row['Q25_APE']:5.2f}%, {row['Q75_APE']:5.2f}%], \"\n",
    "                      f\"N={row['Count']:6d}\")\n",
    "\n",
    "    # Save detailed checkpoints\n",
    "    save_path = \"/Dinor_revision/new_phantom/dinor_train/code_addition/phanton_comp/\"\n",
    "\n",
    "    # Save comprehensive APE data\n",
    "    ape_csv_filename = f\"{save_path}/ape_comprehensive_data_with_IQR.csv\"\n",
    "    ape_df.to_csv(ape_csv_filename, index=False)\n",
    "\n",
    "    # Save summary statistics\n",
    "    summary_csv_filename = f\"{save_path}/ape_summary_statistics_with_IQR.csv\"\n",
    "    summary_table.to_csv(summary_csv_filename, index=False)\n",
    "\n",
    "    print(f\"\\nResults saved:\")\n",
    "    print(f\"- Comprehensive APE data: '{ape_csv_filename}'\")\n",
    "    print(f\"- Summary statistics: '{summary_csv_filename}'\")\n",
    "\n",
    "    return ape_results, ape_df, summary_table\n",
    "\n",
    "# To run the complete APE analysis:\n",
    "ape_results, ape_df, summary_table = run_ape_analysis()"
   ],
   "id": "54d8c940260acb0f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "def calculate_ape_slice_based(y_pred, y_true, method_name, param_idx):\n",
    "    \"\"\"\n",
    "    Calculate Absolute Percentage Error (APE) based on slice averages\n",
    "    APE = |y_true_avg - y_pred_avg| / |y_true_avg| * 100\n",
    "    Returns one APE value per slice (12 values total)\n",
    "    \"\"\"\n",
    "    # Apply scaling based on method type\n",
    "    gt_method = 'gt'\n",
    "    pred_method = get_method_type(method_name)\n",
    "\n",
    "    # Scale both GT and predicted data\n",
    "    y_true_scaled = apply_scaling(y_true.copy(), gt_method, param_idx)\n",
    "    y_pred_scaled = apply_scaling(y_pred.copy(), pred_method, param_idx)\n",
    "\n",
    "    if y_true_scaled.ndim == 3:\n",
    "        # Find slice dimension with 12 slices\n",
    "        slice_dim = None\n",
    "        for dim in [0, 1, 2]:\n",
    "            if y_true_scaled.shape[dim] == 12:\n",
    "                slice_dim = dim\n",
    "                break\n",
    "\n",
    "        if slice_dim is None:\n",
    "            slice_dim = -1\n",
    "        n_slices = y_true_scaled.shape[slice_dim]\n",
    "\n",
    "    elif y_true_scaled.ndim == 2:\n",
    "        n_slices = 1\n",
    "        slice_dim = None\n",
    "    else:\n",
    "        return np.array([])\n",
    "\n",
    "    slice_ape_values = []\n",
    "\n",
    "    for slice_idx in range(n_slices):\n",
    "        # Extract current slice based on slice dimension\n",
    "        if y_true_scaled.ndim == 3:\n",
    "            if slice_dim == 0:\n",
    "                true_slice = y_true_scaled[slice_idx, :, :]\n",
    "                pred_slice = y_pred_scaled[slice_idx, :, :]\n",
    "            elif slice_dim == 1:\n",
    "                true_slice = y_true_scaled[:, slice_idx, :]\n",
    "                pred_slice = y_pred_scaled[:, slice_idx, :]\n",
    "            else:  # slice_dim == 2 or -1\n",
    "                true_slice = y_true_scaled[:, :, slice_idx]\n",
    "                pred_slice = y_pred_scaled[:, :, slice_idx]\n",
    "        else:\n",
    "            true_slice = y_true_scaled\n",
    "            pred_slice = y_pred_scaled\n",
    "\n",
    "        # Get valid pixels in this slice\n",
    "        valid_mask = (~np.isnan(pred_slice) &\n",
    "                      ~np.isnan(true_slice) &\n",
    "                      (np.abs(true_slice) > 1e-10))\n",
    "\n",
    "        n_valid = np.sum(valid_mask)\n",
    "\n",
    "        if n_valid < 5:  # Need at least 5 valid pixels per slice\n",
    "            continue\n",
    "\n",
    "        # Calculate slice averages for valid pixels only\n",
    "        true_slice_avg = np.mean(true_slice[valid_mask])\n",
    "        pred_slice_avg = np.mean(pred_slice[valid_mask])\n",
    "\n",
    "        # Calculate APE for this slice\n",
    "        if np.abs(true_slice_avg) > 1e-10:\n",
    "            slice_ape = np.abs(true_slice_avg - pred_slice_avg) / np.abs(true_slice_avg) * 100\n",
    "\n",
    "            # Remove unrealistic values\n",
    "            if slice_ape <= 500:\n",
    "                slice_ape_values.append(slice_ape)\n",
    "\n",
    "    return np.array(slice_ape_values)\n",
    "\n",
    "def calculate_all_ape_phantom_slice_based(gt, tbmf_selective, y_nikita_6_masked, y_nikita_30_masked,\n",
    "                                         y_alex_nbmf_6_masked, y_alex_nbmf_30_masked,\n",
    "                                         y_alex_vbmf_6_masked, y_alex_vbmf_30_masked):\n",
    "    \"\"\"\n",
    "    Calculate slice-based APE for all methods and parameters\n",
    "    \"\"\"\n",
    "    # Define methods to compare\n",
    "    methods_to_compare = {\n",
    "        'TBMF': {\n",
    "            'data': (gt, tbmf_selective, 6),\n",
    "            'n_params': 6\n",
    "        },\n",
    "        'DOT_6': {\n",
    "            'data': (gt, y_nikita_6_masked, 6),\n",
    "            'n_params': 6\n",
    "        },\n",
    "        'DOT_30': {\n",
    "            'data': (gt, y_nikita_30_masked, 6),\n",
    "            'n_params': 6\n",
    "        },\n",
    "        'NBMF_6': {\n",
    "            'data': (gt[:2], y_alex_nbmf_6_masked, 2),\n",
    "            'n_params': 2\n",
    "        },\n",
    "        'NBMF_30': {\n",
    "            'data': (gt[:2], y_alex_nbmf_30_masked, 2),\n",
    "            'n_params': 2\n",
    "        },\n",
    "        'VBMF_6': {\n",
    "            'data': (gt[:2], y_alex_vbmf_6_masked, 2),\n",
    "            'n_params': 2\n",
    "        },\n",
    "        'VBMF_30': {\n",
    "            'data': (gt[:2], y_alex_vbmf_30_masked, 2),\n",
    "            'n_params': 2\n",
    "        }\n",
    "    }\n",
    "\n",
    "    param_names = ['K_sw', 'f_s', 'B_0', 'B_1', 'T_1', 'T_2']\n",
    "    param_units = ['(S)', '(%)', '(ppm)', '(rel.)', '(ms)', '(ms)']\n",
    "\n",
    "    ape_data = []\n",
    "    ape_results = {}\n",
    "\n",
    "    print(\"Calculating slice-based APE for all methods and parameters...\")\n",
    "\n",
    "    for method_name, method_info in methods_to_compare.items():\n",
    "        print(f\"Processing {method_name}...\")\n",
    "\n",
    "        gt_data, pred_data, n_params = method_info['data']\n",
    "        n_params = method_info['n_params']\n",
    "        ape_results[method_name] = {}\n",
    "\n",
    "        for param_idx in range(n_params):\n",
    "            # Skip B1 for DOT methods (index 3)\n",
    "            if method_name.startswith('DOT') and param_idx == 3:\n",
    "                ape_results[method_name][param_idx] = np.array([])\n",
    "                continue\n",
    "\n",
    "            param_name = param_names[param_idx]\n",
    "\n",
    "            try:\n",
    "                gt_param = gt_data[param_idx]\n",
    "                pred_param = pred_data[param_idx]\n",
    "\n",
    "                # Calculate slice-based APE\n",
    "                ape_values = calculate_ape_slice_based(pred_param, gt_param, method_name, param_idx)\n",
    "                ape_results[method_name][param_idx] = ape_values\n",
    "\n",
    "                if len(ape_values) > 0:\n",
    "                    median_ape = np.median(ape_values)\n",
    "                    q25_ape = np.percentile(ape_values, 25)\n",
    "                    q75_ape = np.percentile(ape_values, 75)\n",
    "                    mean_ape = np.mean(ape_values)\n",
    "\n",
    "                    print(f\"  {param_name}: {len(ape_values)} slices, \"\n",
    "                          f\"Median APE: {median_ape:.2f}%, \"\n",
    "                          f\"Mean APE: {mean_ape:.2f}%, \"\n",
    "                          f\"IQR: [{q25_ape:.2f}%, {q75_ape:.2f}%]\")\n",
    "\n",
    "                    # Store data for plotting\n",
    "                    for slice_idx, ape_val in enumerate(ape_values):\n",
    "                        ape_data.append({\n",
    "                            'Method': method_name,\n",
    "                            'Parameter': param_name,\n",
    "                            'Parameter_Index': param_idx,\n",
    "                            'Slice': slice_idx,\n",
    "                            'APE': ape_val\n",
    "                        })\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"    ERROR processing parameter {param_idx}: {str(e)}\")\n",
    "                ape_results[method_name][param_idx] = np.array([])\n",
    "\n",
    "    return ape_results, pd.DataFrame(ape_data), param_names, param_units\n",
    "\n",
    "def create_ape_boxplots_slice_based_with_points(ape_results, ape_df, param_names, param_units,\n",
    "                                               save_path=\"/home/sahar/Models/Dinor_revision/new_phantom/dinor_train/code_addition/phanton_comp/\"):\n",
    "    \"\"\"\n",
    "    Create boxplots for slice-based APE values with individual data points overlaid\n",
    "    \"\"\"\n",
    "    # Define colors for each method\n",
    "    method_colors = {\n",
    "        'TBMF': '#1f77b4',      # Blue\n",
    "        'DOT_6': '#ff7f0e',     # Orange\n",
    "        'DOT_30': '#d62728',    # Red\n",
    "        'NBMF_6': '#2ca02c',    # Green\n",
    "        'NBMF_30': '#9467bd',   # Purple\n",
    "        'VBMF_6': '#8c564b',    # Brown\n",
    "        'VBMF_30': '#e377c2'    # Pink\n",
    "    }\n",
    "\n",
    "    # Create figure with black background\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12), facecolor='black')\n",
    "    fig.suptitle('Slice-based Absolute Percentage Error (APE) by Parameter and Method',\n",
    "                 fontsize=16, fontweight='bold', color='white')\n",
    "\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for param_idx in range(6):\n",
    "        ax = axes[param_idx]\n",
    "        ax.set_facecolor('black')  # Set subplot background to black\n",
    "\n",
    "        if param_idx == 3:\n",
    "            ax.axis(\"off\")\n",
    "            continue\n",
    "\n",
    "        # Filter data for current parameter\n",
    "        param_data = ape_df[ape_df['Parameter_Index'] == param_idx]\n",
    "\n",
    "        if param_data.empty:\n",
    "            ax.text(0.5, 0.5, f'No data for\\n{param_names[param_idx]}',\n",
    "                   transform=ax.transAxes, ha='center', va='center',\n",
    "                   fontsize=12, color='white')\n",
    "            ax.set_title(f'{param_names[param_idx]} {param_units[param_idx]}',\n",
    "                        fontweight='bold', color='white')\n",
    "            continue\n",
    "\n",
    "        # Create boxplot without outliers\n",
    "        methods_present = param_data['Method'].unique()\n",
    "        colors_for_plot = [method_colors[method] for method in methods_present]\n",
    "\n",
    "        bp = ax.boxplot([param_data[param_data['Method'] == method]['APE'].values\n",
    "                        for method in methods_present],\n",
    "                       tick_labels=methods_present,\n",
    "                       patch_artist=True,\n",
    "                       showfliers=False,\n",
    "                       medianprops={'color': 'white', 'linewidth': 2},\n",
    "                       boxprops={'color': 'white'},\n",
    "                       whiskerprops={'color': 'white'},\n",
    "                       capprops={'color': 'white'})\n",
    "\n",
    "        # Color the boxes\n",
    "        for patch, color in zip(bp['boxes'], colors_for_plot):\n",
    "            patch.set_facecolor('none')  # Remove fill color\n",
    "            patch.set_edgecolor(\"black\")   # Keep colored outline\n",
    "            patch.set_linewidth(2)       # Make outline more visible\n",
    "\n",
    "        # Add individual data points\n",
    "        for i, method in enumerate(methods_present):\n",
    "            method_data = param_data[param_data['Method'] == method]['APE'].values\n",
    "            x_coords = np.random.normal(i + 1, 0.04, len(method_data))\n",
    "            ax.scatter(x_coords, method_data,\n",
    "                      color=method_colors[method],\n",
    "                      alpha=0.7,\n",
    "                      s=30,\n",
    "                      edgecolors='white',\n",
    "                      linewidth=0.5,\n",
    "                      zorder=3)\n",
    "\n",
    "        # Customize the plot\n",
    "        ax.set_title(f'{param_names[param_idx]} {param_units[param_idx]}',\n",
    "                    fontweight='bold', color='white')\n",
    "        ax.set_ylabel('APE (%) - Slice Average', color='white')\n",
    "        ax.grid(True, alpha=0.3, color='gray')\n",
    "        ax.tick_params(axis='x', rotation=45, colors='white')\n",
    "        ax.tick_params(axis='y', colors='white')\n",
    "\n",
    "        # Set reasonable y-axis limits\n",
    "        if len(param_data) > 0:\n",
    "            y_max = np.percentile(param_data['APE'], 95)\n",
    "            ax.set_ylim(0, max(y_max * 1.2, np.max(param_data['APE']) * 1.1))\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the plot\n",
    "    plot_filename = f\"{save_path}/ape_boxplots_slice_based_with_points_black.png\"\n",
    "    plt.savefig(plot_filename, dpi=300, bbox_inches='tight', facecolor='black')\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Slice-based APE boxplots with points saved to: {plot_filename}\")\n",
    "\n",
    "def create_method_comparison_boxplot_slice_based_with_points(ape_df, save_path=\"/home/sahar/Models/Dinor_revision/new_phantom/dinor_train/code_addition/phanton_comp/\"):\n",
    "    \"\"\"\n",
    "    Create a single boxplot comparing all methods with points colored by parameter, ordered by performance\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(14, 10), facecolor='white')\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_facecolor('white')\n",
    "\n",
    "    # Define colors for each method\n",
    "    method_colors = {\n",
    "        'TBMF': '#1f77b4',      # Blue\n",
    "        'DOT_6': '#ff7f0e',     # Orange\n",
    "        'DOT_30': '#d62728',    # Red\n",
    "        'NBMF_6': '#2ca02c',    # Green\n",
    "        'NBMF_30': '#9467bd',   # Purple\n",
    "        'VBMF_6': '#8c564b',    # Brown\n",
    "        'VBMF_30': '#e377c2'    # Pink\n",
    "    }\n",
    "\n",
    "    # Define colors for each parameter\n",
    "    param_colors = {\n",
    "        'K_sw': '#1f77b4',     # Blue\n",
    "        'f_s': '#ff7f0e',       # Orange\n",
    "        'B_0': '#2ca02c',       # Green\n",
    "        'B_1': '#d62728',       # Red\n",
    "        'T_1': '#9467bd',       # Purple\n",
    "        'T_2': '#8c564b'        # Brown\n",
    "    }\n",
    "\n",
    "    # Calculate median APE for each method and sort from best to worst\n",
    "    method_medians = []\n",
    "    for method in ape_df['Method'].unique():\n",
    "        method_data = ape_df[ape_df['Method'] == method]['APE']\n",
    "        median_ape = np.median(method_data)\n",
    "        method_medians.append((method, median_ape))\n",
    "\n",
    "    # Sort by median APE (ascending - best to worst)\n",
    "    method_medians.sort(key=lambda x: x[1])\n",
    "    methods_present = [method for method, _ in method_medians]\n",
    "\n",
    "    colors_for_plot = [method_colors[method] for method in methods_present]\n",
    "\n",
    "    # Create boxplot with boxes visible\n",
    "    bp = ax.boxplot([ape_df[ape_df['Method'] == method]['APE'].values\n",
    "                     for method in methods_present],\n",
    "                    tick_labels=methods_present,\n",
    "                    patch_artist=True,\n",
    "                    showfliers=False,\n",
    "                    medianprops={'color': 'black', 'linewidth': 2},\n",
    "                    boxprops={'color': 'black'},\n",
    "                    whiskerprops={'color': 'black'},\n",
    "                    capprops={'color': 'black'})\n",
    "\n",
    "    # Make boxes transparent (no fill)\n",
    "    for patch, color in zip(bp['boxes'], colors_for_plot):\n",
    "        patch.set_facecolor('none')  # Remove fill color\n",
    "        patch.set_edgecolor(\"black\")   # Keep colored outline\n",
    "        patch.set_linewidth(2)       # Make outline more visible\n",
    "\n",
    "    # Add individual data points colored by parameter\n",
    "    for i, method in enumerate(methods_present):\n",
    "        method_data = ape_df[ape_df['Method'] == method]\n",
    "\n",
    "        for param in method_data['Parameter'].unique():\n",
    "            param_data = method_data[method_data['Parameter'] == param]\n",
    "            x_coords = np.random.normal(i + 1, 0.08, len(param_data))\n",
    "            ax.scatter(x_coords, param_data['APE'].values,\n",
    "                       color=param_colors[param],\n",
    "                       alpha=0.8,\n",
    "                       s=50,\n",
    "                       edgecolors='black',\n",
    "                       linewidth=0.5,\n",
    "                       label=param if i == 0 else \"\",\n",
    "                       zorder=3)\n",
    "\n",
    "    ax.set_title('Overall Slice-based APE Comparison Across All Methods and Parameters\\n(Ordered by performance, points colored by parameter)',\n",
    "                fontsize=14, fontweight='bold', color='black')\n",
    "    ax.set_ylabel('APE (%) - Slice Average', color='black')\n",
    "    ax.set_xlabel('Method', color='black')\n",
    "    ax.grid(True, alpha=0.3, color='gray')\n",
    "    ax.tick_params(axis='x', rotation=45, colors='black')\n",
    "    ax.tick_params(axis='y', colors='black')\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_color('black')\n",
    "        spine.set_linewidth(1)\n",
    "\n",
    "    # Set reasonable y-axis limits\n",
    "    y_max = np.percentile(ape_df['APE'], 95)\n",
    "    ax.set_ylim(0, max(y_max * 1.5, np.max(ape_df['APE']) * 1.1))\n",
    "\n",
    "    # Add legend for parameters inside the plot with no background\n",
    "    legend_elements = [plt.scatter([], [], color=param_colors[param], s=60, alpha=0.8,\n",
    "                                 edgecolors='black', linewidth=0.5, label=param)\n",
    "                      for param in sorted(param_colors.keys())]\n",
    "    legend = ax.legend(handles=legend_elements, title='Parameters',\n",
    "                      loc='upper right', frameon=False)  # frameon=False removes white box\n",
    "    legend.get_title().set_color('black')\n",
    "    for text in legend.get_texts():\n",
    "        text.set_color('black')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the plot\n",
    "    plot_filename = f\"{save_path}/ape_boxplots_slice_based_overall_with_points_ordered_black.png\"\n",
    "    plt.savefig(plot_filename, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Overall slice-based APE comparison with points (ordered) saved to: {plot_filename}\")\n",
    "\n",
    "def create_ape_summary_table_slice_based(ape_df):\n",
    "    \"\"\"\n",
    "    Create a summary table with slice-based APE statistics\n",
    "    \"\"\"\n",
    "    summary_stats = []\n",
    "\n",
    "    for param_name in ape_df['Parameter'].unique():\n",
    "        param_data = ape_df[ape_df['Parameter'] == param_name]\n",
    "\n",
    "        for method in param_data['Method'].unique():\n",
    "            method_data = param_data[param_data['Method'] == method]['APE']\n",
    "\n",
    "            if len(method_data) > 0:\n",
    "                summary_stats.append({\n",
    "                    'Parameter': param_name,\n",
    "                    'Method': method,\n",
    "                    'N_Slices': len(method_data),\n",
    "                    'Mean_APE': np.mean(method_data),\n",
    "                    'Median_APE': np.median(method_data),\n",
    "                    'Q25_APE': np.percentile(method_data, 25),\n",
    "                    'Q75_APE': np.percentile(method_data, 75),\n",
    "                    'Min_APE': np.min(method_data),\n",
    "                    'Max_APE': np.max(method_data),\n",
    "                    'Std_APE': np.std(method_data)\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(summary_stats)\n",
    "\n",
    "def run_ape_analysis_slice_based_with_points():\n",
    "    \"\"\"\n",
    "    Main function to run complete slice-based APE analysis with individual points\n",
    "    \"\"\"\n",
    "    # Calculate slice-based APE for all methods and parameters\n",
    "    ape_results, ape_df, param_names, param_units = calculate_all_ape_phantom_slice_based(\n",
    "        gt, tbmf_selective, y_nikita_6_masked, y_nikita_30_masked,\n",
    "        y_alex_nbmf_6_masked, y_alex_nbmf_30_masked,\n",
    "        y_alex_vbmf_6_masked, y_alex_vbmf_30_masked\n",
    "    )\n",
    "\n",
    "    # Create boxplots by parameter with individual points\n",
    "    create_ape_boxplots_slice_based_with_points(ape_results, ape_df, param_names, param_units)\n",
    "\n",
    "    # Create overall method comparison with points colored by parameter\n",
    "    create_method_comparison_boxplot_slice_based_with_points(ape_df)\n",
    "\n",
    "    # Create summary table\n",
    "    summary_table = create_ape_summary_table_slice_based(ape_df)\n",
    "\n",
    "    # Display summary statistics\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"SLICE-BASED APE SUMMARY STATISTICS\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Show summary for each parameter\n",
    "    for param in param_names[:6]:\n",
    "        param_summary = summary_table[summary_table['Parameter'] == param]\n",
    "        if not param_summary.empty:\n",
    "            print(f\"\\n{param}:\")\n",
    "            print(\"-\" * 40)\n",
    "            for _, row in param_summary.iterrows():\n",
    "                print(f\"  {row['Method']:10}: \"\n",
    "                      f\"Median={row['Median_APE']:6.2f}%, \"\n",
    "                      f\"Mean={row['Mean_APE']:6.2f}%, \"\n",
    "                      f\"IQR=[{row['Q25_APE']:5.2f}%, {row['Q75_APE']:5.2f}%], \"\n",
    "                      f\"N_slices={row['N_Slices']:2d}\")\n",
    "\n",
    "    # Save detailed checkpoints\n",
    "    save_path = \"/Dinor_revision/new_phantom/dinor_train/code_addition/phanton_comp/\"\n",
    "\n",
    "    # Save comprehensive APE data\n",
    "    ape_csv_filename = f\"{save_path}/ape_slice_based_comprehensive_data_with_points.csv\"\n",
    "    ape_df.to_csv(ape_csv_filename, index=False)\n",
    "\n",
    "    # Save summary statistics\n",
    "    summary_csv_filename = f\"{save_path}/ape_slice_based_summary_statistics_with_points.csv\"\n",
    "    summary_table.to_csv(summary_csv_filename, index=False)\n",
    "\n",
    "    print(f\"\\nResults saved:\")\n",
    "    print(f\"- Comprehensive slice-based APE data: '{ape_csv_filename}'\")\n",
    "    print(f\"- Summary statistics: '{summary_csv_filename}'\")\n",
    "\n",
    "    return ape_results, ape_df, summary_table\n",
    "\n",
    "# To run the complete slice-based APE analysis with individual points:\n",
    "ape_results, ape_df, summary_table = run_ape_analysis_slice_based_with_points()"
   ],
   "id": "5ef1653ff70250d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# one way anova",
   "id": "185500fe15313b43"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Patch\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import f_oneway\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "def calculate_ape_slice_based(y_pred, y_true, method_name, param_idx):\n",
    "    \"\"\"\n",
    "    Calculate Absolute Percentage Error (APE) based on slice averages\n",
    "    APE = |y_true_avg - y_pred_avg| / |y_true_avg| * 100\n",
    "    Returns one APE value per slice (12 values total)\n",
    "    \"\"\"\n",
    "    # Apply scaling based on method type\n",
    "    gt_method = 'gt'\n",
    "    pred_method = get_method_type(method_name)\n",
    "\n",
    "    # Scale both GT and predicted data\n",
    "    y_true_scaled = apply_scaling(y_true.copy(), gt_method, param_idx)\n",
    "    y_pred_scaled = apply_scaling(y_pred.copy(), pred_method, param_idx)\n",
    "\n",
    "    if y_true_scaled.ndim == 3:\n",
    "        # Find slice dimension with 12 slices\n",
    "        slice_dim = None\n",
    "        for dim in [0, 1, 2]:\n",
    "            if y_true_scaled.shape[dim] == 12:\n",
    "                slice_dim = dim\n",
    "                break\n",
    "\n",
    "        if slice_dim is None:\n",
    "            slice_dim = -1\n",
    "        n_slices = y_true_scaled.shape[slice_dim]\n",
    "\n",
    "    elif y_true_scaled.ndim == 2:\n",
    "        n_slices = 1\n",
    "        slice_dim = None\n",
    "    else:\n",
    "        return np.array([])\n",
    "\n",
    "    slice_ape_values = []\n",
    "\n",
    "    for slice_idx in range(n_slices):\n",
    "        # Extract current slice based on slice dimension\n",
    "        if y_true_scaled.ndim == 3:\n",
    "            if slice_dim == 0:\n",
    "                true_slice = y_true_scaled[slice_idx, :, :]\n",
    "                pred_slice = y_pred_scaled[slice_idx, :, :]\n",
    "            elif slice_dim == 1:\n",
    "                true_slice = y_true_scaled[:, slice_idx, :]\n",
    "                pred_slice = y_pred_scaled[:, slice_idx, :]\n",
    "            else:  # slice_dim == 2 or -1\n",
    "                true_slice = y_true_scaled[:, :, slice_idx]\n",
    "                pred_slice = y_pred_scaled[:, :, slice_idx]\n",
    "        else:\n",
    "            true_slice = y_true_scaled\n",
    "            pred_slice = y_pred_scaled\n",
    "\n",
    "        # Get valid pixels in this slice\n",
    "        valid_mask = (~np.isnan(pred_slice) &\n",
    "                      ~np.isnan(true_slice) &\n",
    "                      (np.abs(true_slice) > 1e-10))\n",
    "\n",
    "        n_valid = np.sum(valid_mask)\n",
    "\n",
    "        if n_valid < 5:  # Need at least 5 valid pixels per slice\n",
    "            continue\n",
    "\n",
    "        # Calculate slice averages for valid pixels only\n",
    "        true_slice_avg = np.mean(true_slice[valid_mask])\n",
    "        pred_slice_avg = np.mean(pred_slice[valid_mask])\n",
    "\n",
    "        # Calculate APE for this slice\n",
    "        if np.abs(true_slice_avg) > 1e-10:\n",
    "            slice_ape = np.abs(true_slice_avg - pred_slice_avg) / np.abs(true_slice_avg) * 100\n",
    "\n",
    "            # Remove unrealistic values\n",
    "            if slice_ape <= 500:\n",
    "                slice_ape_values.append(slice_ape)\n",
    "\n",
    "    return np.array(slice_ape_values)\n",
    "\n",
    "def calculate_all_ape_phantom_slice_based(gt, tbmf_selective, y_nikita_6_masked, y_nikita_30_masked,\n",
    "                                         y_alex_nbmf_6_masked, y_alex_nbmf_30_masked,\n",
    "                                         y_alex_vbmf_6_masked, y_alex_vbmf_30_masked):\n",
    "    \"\"\"\n",
    "    Calculate slice-based APE for all methods and parameters\n",
    "    \"\"\"\n",
    "    # Define methods to compare\n",
    "    methods_to_compare = {\n",
    "        'TBMF': {\n",
    "            'data': (gt, tbmf_selective, 6),\n",
    "            'n_params': 6\n",
    "        },\n",
    "        'DOT_6': {\n",
    "            'data': (gt, y_nikita_6_masked, 6),\n",
    "            'n_params': 6\n",
    "        },\n",
    "        'DOT_30': {\n",
    "            'data': (gt, y_nikita_30_masked, 6),\n",
    "            'n_params': 6\n",
    "        },\n",
    "        'NBMF_6': {\n",
    "            'data': (gt[:2], y_alex_nbmf_6_masked, 2),\n",
    "            'n_params': 2\n",
    "        },\n",
    "        'NBMF_30': {\n",
    "            'data': (gt[:2], y_alex_nbmf_30_masked, 2),\n",
    "            'n_params': 2\n",
    "        },\n",
    "        'VBMF_6': {\n",
    "            'data': (gt[:2], y_alex_vbmf_6_masked, 2),\n",
    "            'n_params': 2\n",
    "        },\n",
    "        'VBMF_30': {\n",
    "            'data': (gt[:2], y_alex_vbmf_30_masked, 2),\n",
    "            'n_params': 2\n",
    "        }\n",
    "    }\n",
    "\n",
    "    param_names = ['K_sw', 'f_s', 'B_0', 'B_1', 'T_1', 'T_2']\n",
    "    param_units = ['(S)', '(%)', '(ppm)', '(rel.)', '(ms)', '(ms)']\n",
    "\n",
    "    ape_data = []\n",
    "    ape_results = {}\n",
    "\n",
    "    print(\"Calculating slice-based APE for all methods and parameters...\")\n",
    "\n",
    "    for method_name, method_info in methods_to_compare.items():\n",
    "        print(f\"Processing {method_name}...\")\n",
    "\n",
    "        gt_data, pred_data, n_params = method_info['data']\n",
    "        n_params = method_info['n_params']\n",
    "        ape_results[method_name] = {}\n",
    "\n",
    "        for param_idx in range(n_params):\n",
    "            # Skip B1 for DOT methods (index 3)\n",
    "            if method_name.startswith('DOT') and param_idx == 3:\n",
    "                ape_results[method_name][param_idx] = np.array([])\n",
    "                continue\n",
    "\n",
    "            param_name = param_names[param_idx]\n",
    "\n",
    "            try:\n",
    "                gt_param = gt_data[param_idx]\n",
    "                pred_param = pred_data[param_idx]\n",
    "\n",
    "                # Calculate slice-based APE\n",
    "                ape_values = calculate_ape_slice_based(pred_param, gt_param, method_name, param_idx)\n",
    "                ape_results[method_name][param_idx] = ape_values\n",
    "\n",
    "                if len(ape_values) > 0:\n",
    "                    median_ape = np.median(ape_values)\n",
    "                    q25_ape = np.percentile(ape_values, 25)\n",
    "                    q75_ape = np.percentile(ape_values, 75)\n",
    "                    mean_ape = np.mean(ape_values)\n",
    "\n",
    "                    print(f\"  {param_name}: {len(ape_values)} slices, \"\n",
    "                          f\"Median APE: {median_ape:.2f}%, \"\n",
    "                          f\"Mean APE: {mean_ape:.2f}%, \"\n",
    "                          f\"IQR: [{q25_ape:.2f}%, {q75_ape:.2f}%]\")\n",
    "\n",
    "                    # Store data for plotting\n",
    "                    for slice_idx, ape_val in enumerate(ape_values):\n",
    "                        ape_data.append({\n",
    "                            'Method': method_name,\n",
    "                            'Parameter': param_name,\n",
    "                            'Parameter_Index': param_idx,\n",
    "                            'Slice': slice_idx,\n",
    "                            'APE': ape_val\n",
    "                        })\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"    ERROR processing parameter {param_idx}: {str(e)}\")\n",
    "                ape_results[method_name][param_idx] = np.array([])\n",
    "\n",
    "    return ape_results, pd.DataFrame(ape_data), param_names, param_units\n",
    "\n",
    "def perform_overall_anova_analysis_tbmf_focused(ape_df, save_path=\"/home/sahar/Models/Dinor_revision/new_phantom/dinor_train/code_addition/phanton_comp/\"):\n",
    "    \"\"\"\n",
    "    Perform overall ANOVA analysis across all methods and parameters combined,\n",
    "    but only display TBMF comparisons in the checkpoints\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"OVERALL ANOVA ANALYSIS - TBMF vs ALL OTHER METHODS\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Prepare data for overall ANOVA\n",
    "    methods = ape_df['Method'].unique()\n",
    "    all_ape_values = []\n",
    "    all_method_labels = []\n",
    "\n",
    "    # Collect all APE values for each method\n",
    "    method_data = {}\n",
    "    for method in methods:\n",
    "        method_ape = ape_df[ape_df['Method'] == method]['APE'].values\n",
    "        method_data[method] = method_ape\n",
    "        all_ape_values.extend(method_ape)\n",
    "        all_method_labels.extend([method] * len(method_ape))\n",
    "\n",
    "    # Perform overall one-way ANOVA\n",
    "    groups = [method_data[method] for method in methods]\n",
    "    f_stat, p_value = f_oneway(*groups)\n",
    "\n",
    "    # Determine significance level\n",
    "    if p_value < 0.0001:\n",
    "        significance = \"****\"\n",
    "        p_display = \"p < 0.0001\"\n",
    "    elif p_value < 0.001:\n",
    "        significance = \"***\"\n",
    "        p_display = f\"p = {p_value:.4f}\"\n",
    "    elif p_value < 0.01:\n",
    "        significance = \"**\"\n",
    "        p_display = f\"p = {p_value:.4f}\"\n",
    "    elif p_value < 0.05:\n",
    "        significance = \"*\"\n",
    "        p_display = f\"p = {p_value:.4f}\"\n",
    "    else:\n",
    "        significance = \"ns\"\n",
    "        p_display = f\"p = {p_value:.4f}\"\n",
    "\n",
    "    print(f\"Overall One-way ANOVA: F({len(methods)-1}, {len(all_ape_values)-len(methods)}) = {f_stat:.2f}, {p_display}\")\n",
    "    print(f\"Significance: {significance}\")\n",
    "\n",
    "    # Perform Tukey's HSD test if significant, but only show TBMF checkpoints\n",
    "    tukey_results_overall = None\n",
    "    tbmf_comparisons = []\n",
    "\n",
    "    if p_value < 0.05:\n",
    "        # Perform Tukey's HSD test\n",
    "        tukey_results_overall = pairwise_tukeyhsd(endog=all_ape_values, groups=all_method_labels, alpha=0.05)\n",
    "\n",
    "        # Parse checkpoints and extract only TBMF comparisons\n",
    "        for i in range(len(tukey_results_overall.summary().data) ):\n",
    "            if i == 0:  # Skip header row\n",
    "                continue\n",
    "            row = tukey_results_overall.summary().data[i]\n",
    "            group1, group2, meandiff, p_adj, lower, upper, reject = row\n",
    "\n",
    "            # Only process TBMF-related comparisons\n",
    "            if 'TBMF' in group1 or 'TBMF' in group2:\n",
    "                # Format p-value display\n",
    "                if p_adj < 0.0001:\n",
    "                    p_display = \"< 0.0001\"\n",
    "                    sig_marker = \"****\"\n",
    "                elif p_adj < 0.001:\n",
    "                    p_display = f\"{p_adj:.4f}\"\n",
    "                    sig_marker = \"***\"\n",
    "                elif p_adj < 0.01:\n",
    "                    p_display = f\"{p_adj:.4f}\"\n",
    "                    sig_marker = \"**\"\n",
    "                elif p_adj < 0.05:\n",
    "                    p_display = f\"{p_adj:.4f}\"\n",
    "                    sig_marker = \"*\"\n",
    "                else:\n",
    "                    p_display = f\"{p_adj:.4f}\"\n",
    "                    sig_marker = \"ns\"\n",
    "\n",
    "                tbmf_comparisons.append({\n",
    "                    'Group1': group1,\n",
    "                    'Group2': group2,\n",
    "                    'Mean_Diff': meandiff,\n",
    "                    'P_adj': p_adj,\n",
    "                    'Significant': reject,\n",
    "                    'Significance_Level': sig_marker,\n",
    "                    'P_display': p_display\n",
    "                })\n",
    "\n",
    "        # Display TBMF comparisons only\n",
    "        print(f\"\\n\" + \"=\" * 60)\n",
    "        print(\"TBMF DISTINCTNESS ANALYSIS\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        tbmf_mean = np.mean(method_data['TBMF'])\n",
    "        tbmf_median = np.median(method_data['TBMF'])\n",
    "        print(f\"TBMF Mean APE across all parameters: {tbmf_mean:.2f}%\")\n",
    "        print(f\"TBMF Median APE across all parameters: {tbmf_median:.2f}%\")\n",
    "\n",
    "        print(f\"\\nTBMF vs Other Methods - Tukey's HSD Results:\")\n",
    "        print(f\"{'Method':<12} {'Mean APE':<12} {'Median APE':<12} {'Mean Diff':<15} {'p-value':<12} {'Significance':<12}\")\n",
    "        print(\"-\" * 85)\n",
    "\n",
    "        for comp in tbmf_comparisons:\n",
    "            other_method = comp['Group1'] if comp['Group1'] != 'TBMF' else comp['Group2']\n",
    "            other_mean = np.mean(method_data[other_method])\n",
    "            other_median = np.median(method_data[other_method])\n",
    "            diff = other_mean - tbmf_mean\n",
    "\n",
    "            print(f\"{other_method:<12} {other_mean:<12.2f} {other_median:<12.2f} {diff:+.2f}%        {comp['P_display']:<12} {comp['Significance_Level']:<12}\")\n",
    "\n",
    "    return {\n",
    "        'f_statistic': f_stat,\n",
    "        'p_value': p_value,\n",
    "        'significance': significance,\n",
    "        'tukey_results': tukey_results_overall,\n",
    "        'tbmf_comparisons': tbmf_comparisons,\n",
    "        'method_means': {method: np.mean(data) for method, data in method_data.items()},\n",
    "        'method_medians': {method: np.median(data) for method, data in method_data.items()}\n",
    "    }\n",
    "\n",
    "def create_overall_comparison_plot_with_anova_fixed(ape_df, overall_anova_results,\n",
    "                                                   save_path=\"/home/sahar/Models/Dinor_revision/new_phantom/dinor_train/code_addition/phanton_comp/\"):\n",
    "    \"\"\"\n",
    "    Create the overall comparison plot with ANOVA checkpoints and individual points,\n",
    "    highlighting TBMF's distinctness - SORTED BY MEDIAN APE\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(16, 10), facecolor='white')\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_facecolor('white')\n",
    "\n",
    "    # Define colors for each method - highlight TBMF\n",
    "    method_colors = {\n",
    "        'TBMF': '#FF0000',      # Red - highlighted\n",
    "        'DOT_6': '#ff7f0e',     # Orange\n",
    "        'DOT_30': '#d62728',    # Dark Red\n",
    "        'NBMF_6': '#2ca02c',    # Green\n",
    "        'NBMF_30': '#9467bd',   # Purple\n",
    "        'VBMF_6': '#8c564b',    # Brown\n",
    "        'VBMF_30': '#e377c2'    # Pink\n",
    "    }\n",
    "\n",
    "    # Define colors for each parameter\n",
    "    param_colors = {\n",
    "        'K_sw': '#1f77b4',     # Blue\n",
    "        'f_s': '#ff7f0e',       # Orange\n",
    "        'B_0': '#2ca02c',       # Green\n",
    "        'B_1': '#d62728',       # Red\n",
    "        'T_1': '#9467bd',       # Purple\n",
    "        'T_2': '#8c564b'        # Brown\n",
    "    }\n",
    "\n",
    "    # Calculate median APE for each method and sort in ASCENDING order (lowest median first)\n",
    "    method_medians = []\n",
    "    print(\"\\nMethod median APE calculations:\")\n",
    "    for method in ape_df['Method'].unique():\n",
    "        method_data = ape_df[ape_df['Method'] == method]['APE']\n",
    "        median_ape = np.median(method_data)\n",
    "        mean_ape = np.mean(method_data)\n",
    "        method_medians.append((method, median_ape))\n",
    "        print(f\"  {method}: Median APE = {median_ape:.2f}%, Mean APE = {mean_ape:.2f}%\")\n",
    "\n",
    "    # Sort by median APE in ascending order (lowest first - best performance on left)\n",
    "    method_medians.sort(key=lambda x: x[1])\n",
    "    methods_present = [method for method, _ in method_medians]\n",
    "\n",
    "    print(f\"\\nMethods ordered by ascending median APE (best to worst): {methods_present}\")\n",
    "    print(f\"Corresponding median APEs: {[f'{median:.2f}%' for _, median in method_medians]}\")\n",
    "\n",
    "    colors_for_plot = [method_colors[method] for method in methods_present]\n",
    "\n",
    "    # Create boxplot with enhanced visibility for TBMF\n",
    "    bp = ax.boxplot([ape_df[ape_df['Method'] == method]['APE'].values\n",
    "                     for method in methods_present],\n",
    "                    tick_labels=methods_present,\n",
    "                    patch_artist=True,\n",
    "                    showfliers=False,\n",
    "                    medianprops={'color': 'black', 'linewidth': 2.5},\n",
    "                    boxprops={'color': 'black', 'linewidth': 1.5},\n",
    "                    whiskerprops={'color': 'black', 'linewidth': 1.5},\n",
    "                    capprops={'color': 'black', 'linewidth': 1.5})\n",
    "\n",
    "    # Make all boxes transparent to highlight individual points\n",
    "    for i, (patch, color, method) in enumerate(zip(bp['boxes'], colors_for_plot, methods_present)):\n",
    "        if method == 'TBMF':\n",
    "            patch.set_facecolor(\"none\")\n",
    "            patch.set_edgecolor(\"black\")\n",
    "            patch.set_linewidth(2)  # Thicker border for TBMF\n",
    "        else:\n",
    "            patch.set_facecolor(\"none\")\n",
    "            patch.set_edgecolor(\"black\")\n",
    "            patch.set_linewidth(1.5)\n",
    "\n",
    "    # Add individual data points colored by parameter\n",
    "    for i, method in enumerate(methods_present):\n",
    "        method_data = ape_df[ape_df['Method'] == method]\n",
    "\n",
    "        for param in method_data['Parameter'].unique():\n",
    "            param_data = method_data[method_data['Parameter'] == param]\n",
    "            x_coords = np.random.normal(i + 1, 0.08, len(param_data))\n",
    "\n",
    "            # Special styling for TBMF points\n",
    "            if method == 'TBMF':\n",
    "                ax.scatter(x_coords, param_data['APE'].values,\n",
    "                           color=param_colors[param],\n",
    "                           alpha=0.9,\n",
    "                           s=60,  # Larger points for TBMF\n",
    "                           edgecolors='black',\n",
    "                           linewidth=1,\n",
    "                           label=param if i == 0 else \"\",\n",
    "                           zorder=4,\n",
    "                           marker='o')\n",
    "            else:\n",
    "                ax.scatter(x_coords, param_data['APE'].values,\n",
    "                           color=param_colors[param],\n",
    "                           alpha=0.7,\n",
    "                           s=45,\n",
    "                           edgecolors='black',\n",
    "                           linewidth=0.5,\n",
    "                           label=param if i == 0 else \"\",\n",
    "                           zorder=3)\n",
    "\n",
    "    # Add ANOVA checkpoints to title\n",
    "    anova_title = f\"Overall ANOVA: F = {overall_anova_results['f_statistic']:.2f}, \"\n",
    "    if overall_anova_results['p_value'] < 0.0001:\n",
    "        anova_title += f\"{overall_anova_results['significance']} (p < 0.0001)\"\n",
    "    else:\n",
    "        anova_title += f\"{overall_anova_results['significance']} (p = {overall_anova_results['p_value']:.4f})\"\n",
    "\n",
    "    ax.set_title(f'Overall APE Comparison',\n",
    "                fontsize=14, fontweight='bold', color='black')\n",
    "    ax.set_ylabel('APE (%) - Slice Average', fontsize=12, color='black')\n",
    "    ax.set_xlabel('Method', fontsize=12, color='black')\n",
    "    ax.grid(True, alpha=0.1, color='gray')\n",
    "    ax.tick_params(axis='x', rotation=45, colors='black')\n",
    "    ax.tick_params(axis='y', colors='black')\n",
    "\n",
    "    # Style the axes\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_color('black')\n",
    "        spine.set_linewidth(1)\n",
    "\n",
    "    # Set reasonable y-axis limits\n",
    "    y_max = np.percentile(ape_df['APE'], 95)\n",
    "    ax.set_ylim(0, max(y_max * 1.5, np.max(ape_df['APE']) * 1.1))\n",
    "\n",
    "    # Add significance brackets for TBMF comparisons - FIXED positioning\n",
    "    if overall_anova_results['significance'] != 'ns' and overall_anova_results['tbmf_comparisons']:\n",
    "        y_max_plot = ax.get_ylim()[1]\n",
    "        bracket_height = y_max_plot * 0.02\n",
    "\n",
    "        # Find TBMF position in the sorted list\n",
    "        tbmf_pos = methods_present.index('TBMF') + 1\n",
    "        print(f\"TBMF position in plot: {tbmf_pos}\")\n",
    "\n",
    "        # Add brackets for significant TBMF comparisons\n",
    "        significant_tbmf_comps = [\n",
    "            comp for comp in overall_anova_results['tbmf_comparisons']\n",
    "            if comp['Significant'] and comp['Significance_Level'] in ['****', '***', '**', '*']\n",
    "        ]\n",
    "\n",
    "        # Sort by significance level for better display\n",
    "        sig_order = {'****': 4, '***': 3, '**': 2, '*': 1, 'ns': 0}\n",
    "        significant_tbmf_comps.sort(key=lambda x: sig_order[x['Significance_Level']], reverse=True)\n",
    "        print(significant_tbmf_comps)\n",
    "\n",
    "        for i, comp in enumerate(significant_tbmf_comps):\n",
    "            other_method = comp['Group1'] if comp['Group1'] != 'TBMF' else comp['Group2']\n",
    "            if other_method in methods_present:\n",
    "                other_pos = methods_present.index(other_method) + 1\n",
    "                y = y_max_plot * (0.72 + i * 0.06)  # Better spacing\n",
    "\n",
    "                # Draw bracket\n",
    "                ax.plot([min(tbmf_pos, other_pos), min(tbmf_pos, other_pos),\n",
    "                        max(tbmf_pos, other_pos), max(tbmf_pos, other_pos)],\n",
    "                       [y, y + bracket_height, y + bracket_height, y],\n",
    "                       'k-', linewidth=1.5, alpha=0.8)\n",
    "\n",
    "                # Add significance text\n",
    "                    # Add significance text - show exact p-value if > 0.001\n",
    "                if comp['P_adj'] > 0.001:\n",
    "                        # Show exact p-value for p > 0.001 (includes *, **, and ns)\n",
    "                        display_text = f\"p = {comp['P_adj']:.3f}\"\n",
    "                else:\n",
    "                        # Show asterisks for p  0.001 (*** and ****)\n",
    "                        display_text = comp['Significance_Level']\n",
    "\n",
    "                ax.text((tbmf_pos + other_pos) / 2, y + y_max_plot * 0.025,\n",
    "                           display_text,\n",
    "                           ha='center', va='bottom', fontweight='bold',\n",
    "                           color='red', fontsize=9)\n",
    "\n",
    "    # Add legend for parameters\n",
    "    legend_elements = [plt.scatter([], [], color=param_colors[param], s=60, alpha=0.7,\n",
    "                                 edgecolors='black', linewidth=0.5, label=param)\n",
    "                      for param in sorted(param_colors.keys())]\n",
    "    legend = ax.legend(handles=legend_elements,\n",
    "                      loc='upper right', frameon=False, fancybox=True, shadow=True)\n",
    "    legend.get_title().set_color('black')\n",
    "    legend.get_title().set_fontweight('bold')\n",
    "    for text in legend.get_texts():\n",
    "        text.set_color('black')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the plot\n",
    "    plot_filename = f\"{save_path}overall_anova_comparison_with_tbmf_highlight_median_sorted.png\"\n",
    "    plt.savefig(plot_filename, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Overall ANOVA comparison plot (sorted by median) with TBMF highlighting saved to: {plot_filename}\")\n",
    "\n",
    "def create_ape_summary_table_slice_based(ape_df):\n",
    "    \"\"\"\n",
    "    Create a summary table with slice-based APE statistics\n",
    "    \"\"\"\n",
    "    summary_stats = []\n",
    "\n",
    "    for param_name in ape_df['Parameter'].unique():\n",
    "        param_data = ape_df[ape_df['Parameter'] == param_name]\n",
    "\n",
    "        for method in param_data['Method'].unique():\n",
    "            method_data = param_data[param_data['Method'] == method]['APE']\n",
    "\n",
    "            if len(method_data) > 0:\n",
    "                summary_stats.append({\n",
    "                    'Parameter': param_name,\n",
    "                    'Method': method,\n",
    "                    'N_Slices': len(method_data),\n",
    "                    'Mean_APE': np.mean(method_data),\n",
    "                    'Median_APE': np.median(method_data),\n",
    "                    'Q25_APE': np.percentile(method_data, 25),\n",
    "                    'Q75_APE': np.percentile(method_data, 75),\n",
    "                    'Min_APE': np.min(method_data),\n",
    "                    'Max_APE': np.max(method_data),\n",
    "                    'Std_APE': np.std(method_data)\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(summary_stats)\n",
    "\n",
    "def run_tbmf_focused_anova_analysis():\n",
    "    \"\"\"\n",
    "    Main function to run TBMF-focused ANOVA analysis with median-based sorting\n",
    "    \"\"\"\n",
    "    # Calculate slice-based APE for all methods and parameters\n",
    "    ape_results, ape_df, param_names, param_units = calculate_all_ape_phantom_slice_based(\n",
    "        gt, tbmf_selective, y_nikita_6_masked, y_nikita_30_masked,\n",
    "        y_alex_nbmf_6_masked, y_alex_nbmf_30_masked,\n",
    "        y_alex_vbmf_6_masked, y_alex_vbmf_30_masked\n",
    "    )\n",
    "\n",
    "    # Perform overall ANOVA analysis focusing on TBMF\n",
    "    overall_anova_results = perform_overall_anova_analysis_tbmf_focused(ape_df)\n",
    "\n",
    "    # Create overall comparison plot with median-based sorting\n",
    "    create_overall_comparison_plot_with_anova_fixed(ape_df, overall_anova_results)\n",
    "\n",
    "    # Create summary table\n",
    "    summary_table = create_ape_summary_table_slice_based(ape_df)\n",
    "\n",
    "    # Display summary statistics\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"SLICE-BASED APE SUMMARY STATISTICS\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Show summary for each parameter\n",
    "    for param in param_names[:6]:\n",
    "        param_summary = summary_table[summary_table['Parameter'] == param]\n",
    "        if not param_summary.empty:\n",
    "            print(f\"\\n{param}:\")\n",
    "            print(\"-\" * 40)\n",
    "            for _, row in param_summary.iterrows():\n",
    "                print(f\"  {row['Method']:10}: \"\n",
    "                      f\"Median={row['Median_APE']:6.2f}%, \"\n",
    "                      f\"Mean={row['Mean_APE']:6.2f}%, \"\n",
    "                      f\"IQR=[{row['Q25_APE']:5.2f}%, {row['Q75_APE']:5.2f}%], \"\n",
    "                      f\"N_slices={row['N_Slices']:2d}\")\n",
    "\n",
    "    # Save detailed checkpoints\n",
    "    save_path = \"/Dinor_revision/new_phantom/dinor_train/code_addition/phanton_comp/\"\n",
    "\n",
    "    # Save comprehensive APE data\n",
    "    ape_csv_filename = f\"{save_path}ape_slice_based_comprehensive_data_tbmf_focused_median_sorted.csv\"\n",
    "    ape_df.to_csv(ape_csv_filename, index=False)\n",
    "\n",
    "    # Save summary statistics\n",
    "    summary_csv_filename = f\"{save_path}ape_slice_based_summary_statistics_tbmf_focused_median_sorted.csv\"\n",
    "    summary_table.to_csv(summary_csv_filename, index=False)\n",
    "\n",
    "    # Save ANOVA checkpoints\n",
    "    overall_results_df = pd.DataFrame([{\n",
    "        'Analysis': 'Overall_ANOVA',\n",
    "        'F_statistic': overall_anova_results['f_statistic'],\n",
    "        'P_value': overall_anova_results['p_value'],\n",
    "        'Significance': overall_anova_results['significance']\n",
    "    }])\n",
    "\n",
    "    if overall_anova_results['tbmf_comparisons']:\n",
    "        tbmf_results_df = pd.DataFrame(overall_anova_results['tbmf_comparisons'])\n",
    "        anova_results_filename = f\"{save_path}tbmf_anova_results_median_sorted.csv\"\n",
    "        with open(anova_results_filename, 'w') as f:\n",
    "            f.write(\"Overall ANOVA Results\\n\")\n",
    "            overall_results_df.to_csv(f, index=False)\n",
    "            f.write(\"\\nTBMF Comparisons\\n\")\n",
    "            tbmf_results_df.to_csv(f, index=False)\n",
    "\n",
    "    print(f\"\\nResults saved:\")\n",
    "    print(f\"- Comprehensive slice-based APE data: '{ape_csv_filename}'\")\n",
    "    print(f\"- Summary statistics: '{summary_csv_filename}'\")\n",
    "    if overall_anova_results['tbmf_comparisons']:\n",
    "        print(f\"- TBMF ANOVA checkpoints: '{anova_results_filename}'\")\n",
    "\n",
    "    return ape_results, ape_df, summary_table, overall_anova_results\n",
    "\n",
    "# Run the complete TBMF-focused analysis with median-based sorting\n",
    "if __name__ == \"__main__\":\n",
    "    results = run_tbmf_focused_anova_analysis()"
   ],
   "id": "e8e82ee0230b6177",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def perform_parameter_wise_anova_analysis_tbmf_focused(ape_df, save_path=\"/home/sahar/Models/Dinor_revision/new_phantom/dinor_train/code_addition/phanton_comp/\"):\n",
    "    \"\"\"\n",
    "    Perform ANOVA analysis for each parameter separately, focusing on TBMF comparisons\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"PARAMETER-WISE ANOVA ANALYSIS - TBMF vs OTHER METHODS\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    param_anova_results = {}\n",
    "\n",
    "    # Get unique parameters\n",
    "    parameters = ape_df['Parameter'].unique()\n",
    "\n",
    "    for param in parameters:\n",
    "        print(f\"\\n{'-' * 60}\")\n",
    "        print(f\"PARAMETER: {param}\")\n",
    "        print(f\"{'-' * 60}\")\n",
    "\n",
    "        # Filter data for this parameter\n",
    "        param_data = ape_df[ape_df['Parameter'] == param]\n",
    "\n",
    "        if param_data.empty:\n",
    "            print(f\"No data available for parameter {param}\")\n",
    "            continue\n",
    "\n",
    "        # Get methods available for this parameter\n",
    "        methods = param_data['Method'].unique()\n",
    "\n",
    "        if len(methods) < 2:\n",
    "            print(f\"Not enough methods for comparison (only {len(methods)} methods available)\")\n",
    "            continue\n",
    "\n",
    "        # Prepare data for ANOVA\n",
    "        method_data = {}\n",
    "        for method in methods:\n",
    "            method_ape = param_data[param_data['Method'] == method]['APE'].values\n",
    "            method_data[method] = method_ape\n",
    "\n",
    "        # Perform one-way ANOVA for this parameter\n",
    "        groups = [method_data[method] for method in methods]\n",
    "        f_stat, p_value = f_oneway(*groups)\n",
    "\n",
    "        # Determine significance level\n",
    "        if p_value < 0.0001:\n",
    "            significance = \"****\"\n",
    "            p_display = \"p < 0.0001\"\n",
    "        elif p_value < 0.001:\n",
    "            significance = \"***\"\n",
    "            p_display = f\"p = {p_value:.4f}\"\n",
    "        elif p_value < 0.01:\n",
    "            significance = \"**\"\n",
    "            p_display = f\"p = {p_value:.4f}\"\n",
    "        elif p_value < 0.05:\n",
    "            significance = \"*\"\n",
    "            p_display = f\"p = {p_value:.4f}\"\n",
    "        else:\n",
    "            significance = \"ns\"\n",
    "            p_display = f\"p = {p_value:.4f}\"\n",
    "\n",
    "        print(f\"One-way ANOVA for {param}: F({len(methods)-1}, {len(param_data)-len(methods)}) = {f_stat:.2f}, {p_display}\")\n",
    "        print(f\"Significance: {significance}\")\n",
    "\n",
    "        # Initialize parameter checkpoints\n",
    "        param_anova_results[param] = {\n",
    "            'f_statistic': f_stat,\n",
    "            'p_value': p_value,\n",
    "            'significance': significance,\n",
    "            'methods': list(methods),\n",
    "            'tbmf_comparisons': [],\n",
    "            'method_means': {method: np.mean(data) for method, data in method_data.items()},\n",
    "            'method_medians': {method: np.median(data) for method, data in method_data.items()}\n",
    "        }\n",
    "\n",
    "        # Perform Tukey's HSD test if significant and TBMF is present\n",
    "        if p_value < 0.05 and 'TBMF' in methods:\n",
    "            # Prepare data for Tukey's test\n",
    "            all_ape_values = []\n",
    "            all_method_labels = []\n",
    "            for method in methods:\n",
    "                method_ape = param_data[param_data['Method'] == method]['APE'].values\n",
    "                all_ape_values.extend(method_ape)\n",
    "                all_method_labels.extend([method] * len(method_ape))\n",
    "\n",
    "            # Perform Tukey's HSD test\n",
    "            tukey_results = pairwise_tukeyhsd(endog=all_ape_values, groups=all_method_labels, alpha=0.05)\n",
    "            print(f\"Full Tukey checkpoints for {param}:\")\n",
    "            print(tukey_results.summary())\n",
    "            print(f\"Number of comparisons: {len(tukey_results.summary().data)}\")\n",
    "            for i, row in enumerate(tukey_results.summary().data):\n",
    "                print(f\"Row {i}: {row}\")\n",
    "            param_anova_results[param]['tukey_results'] = tukey_results\n",
    "\n",
    "            # Parse checkpoints and extract only TBMF comparisons\n",
    "            tbmf_comparisons = []\n",
    "            for i in range(len(tukey_results.summary().data) ):\n",
    "                if i == 0:  # Skip header row\n",
    "                    continue\n",
    "                row = tukey_results.summary().data[i]\n",
    "                group1, group2, meandiff, p_adj, lower, upper, reject = row\n",
    "\n",
    "                # Only process TBMF-related comparisons\n",
    "                if 'TBMF' in group1 or 'TBMF' in group2:\n",
    "                    # Format p-value display\n",
    "                    if p_adj < 0.0001:\n",
    "                        p_display = \"< 0.0001\"\n",
    "                        sig_marker = \"****\"\n",
    "                    elif p_adj < 0.001:\n",
    "                        p_display = f\"{p_adj:.4f}\"\n",
    "                        sig_marker = \"***\"\n",
    "                    elif p_adj < 0.01:\n",
    "                        p_display = f\"{p_adj:.4f}\"\n",
    "                        sig_marker = \"**\"\n",
    "                    elif p_adj < 0.05:\n",
    "                        p_display = f\"{p_adj:.4f}\"\n",
    "                        sig_marker = \"*\"\n",
    "                    else:\n",
    "                        p_display = f\"{p_adj:.4f}\"\n",
    "                        sig_marker = \"ns\"\n",
    "\n",
    "                    tbmf_comparisons.append({\n",
    "                        'Group1': group1,\n",
    "                        'Group2': group2,\n",
    "                        'Mean_Diff': meandiff,\n",
    "                        'P_adj': p_adj,\n",
    "                        'Significant': reject,\n",
    "                        'Significance_Level': sig_marker,\n",
    "                        'P_display': p_display\n",
    "                    })\n",
    "\n",
    "            param_anova_results[param]['tbmf_comparisons'] = tbmf_comparisons\n",
    "\n",
    "            # Display TBMF comparisons for this parameter\n",
    "            if 'TBMF' in method_data:\n",
    "                tbmf_mean = np.mean(method_data['TBMF'])\n",
    "                tbmf_median = np.median(method_data['TBMF'])\n",
    "                print(f\"\\nTBMF Performance for {param}:\")\n",
    "                print(f\"  Mean APE: {tbmf_mean:.2f}%\")\n",
    "                print(f\"  Median APE: {tbmf_median:.2f}%\")\n",
    "\n",
    "                if tbmf_comparisons:\n",
    "                    print(f\"\\nTBMF vs Other Methods for {param} - Tukey's HSD Results:\")\n",
    "                    print(f\"{'Method':<12} {'Mean APE':<12} {'Median APE':<12} {'Mean Diff':<15} {'p-value':<12} {'Significance':<12}\")\n",
    "                    print(\"-\" * 85)\n",
    "\n",
    "                    for comp in tbmf_comparisons:\n",
    "                        other_method = comp['Group1'] if comp['Group1'] != 'TBMF' else comp['Group2']\n",
    "                        other_mean = np.mean(method_data[other_method])\n",
    "                        other_median = np.median(method_data[other_method])\n",
    "                        diff = other_mean - tbmf_mean\n",
    "\n",
    "                        print(f\"{other_method:<12} {other_mean:<12.2f} {other_median:<12.2f} {diff:+.2f}%        {comp['P_display']:<12} {comp['Significance_Level']:<12}\")\n",
    "        else:\n",
    "            param_anova_results[param]['tukey_results'] = None\n",
    "\n",
    "    return param_anova_results\n",
    "\n",
    "def create_enhanced_parameter_wise_plots(ape_df, param_anova_results,\n",
    "                                       save_path=\"/home/sahar/Models/Dinor_revision/new_phantom/dinor_train/code_addition/phanton_comp/\"):\n",
    "    \"\"\"\n",
    "    Create enhanced parameter-wise comparison plots with better visibility and significance annotations\n",
    "    \"\"\"\n",
    "    # Define colors for each method - highlight TBMF\n",
    "    method_colors = {\n",
    "        'TBMF': '#0000FF',      # Blue\n",
    "        'DOT_6': '#ff7f0e',     # Orange\n",
    "        'DOT_30': '#d62728',    # Dark Red\n",
    "        'NBMF_6': '#2ca02c',    # Green\n",
    "        'NBMF_30': '#9467bd',   # Purple\n",
    "        'VBMF_6': '#8c564b',    # Brown\n",
    "        'VBMF_30': '#e377c2'    # Pink\n",
    "    }\n",
    "\n",
    "    parameters = ape_df['Parameter'].unique()\n",
    "\n",
    "    # Create figure with better spacing\n",
    "    fig = plt.figure(figsize=(20, 15), facecolor='white')\n",
    "\n",
    "    # Define subplot layout - 2 rows, 3 columns\n",
    "    n_cols = 3\n",
    "    n_rows = 2\n",
    "    y_lims = [100,100,200,20,20,100]\n",
    "\n",
    "    for i, param in enumerate(parameters):\n",
    "\n",
    "        ax = plt.subplot(n_rows, n_cols, i+1)\n",
    "        ax.set_facecolor('white')\n",
    "\n",
    "\n",
    "        # Filter data for this parameter\n",
    "        param_data = ape_df[ape_df['Parameter'] == param]\n",
    "\n",
    "        if param_data.empty:\n",
    "            ax.text(0.5, 0.5, f'No data for {param}', ha='center', va='center',\n",
    "                   transform=ax.transAxes, fontsize=12)\n",
    "            ax.set_title(param, fontsize=14, fontweight='bold')\n",
    "            continue\n",
    "\n",
    "        # Get methods and sort by median APE\n",
    "        methods = param_data['Method'].unique()\n",
    "        method_medians = []\n",
    "        for method in methods:\n",
    "            method_ape = param_data[param_data['Method'] == method]['APE']\n",
    "            median_ape = np.median(method_ape)\n",
    "            method_medians.append((method, median_ape))\n",
    "\n",
    "        # Sort by median APE in ascending order\n",
    "        method_medians.sort(key=lambda x: x[1])\n",
    "        methods_sorted = [method for method, _ in method_medians]\n",
    "\n",
    "        # Create enhanced boxplot\n",
    "        bp = ax.boxplot([param_data[param_data['Method'] == method]['APE'].values\n",
    "                        for method in methods_sorted],\n",
    "                       tick_labels=methods_sorted,\n",
    "                       patch_artist=True,\n",
    "                       showfliers=False,\n",
    "                       medianprops={'color': 'black', 'linewidth': 2.5},\n",
    "                       boxprops={'linewidth': 1.5},\n",
    "                       whiskerprops={'linewidth': 1.5},\n",
    "                       capprops={'linewidth': 1.5})\n",
    "\n",
    "        # Color the boxes with special emphasis on TBMF\n",
    "        for j, (patch, method) in enumerate(zip(bp['boxes'], methods_sorted)):\n",
    "            color = method_colors.get(method, '#808080')\n",
    "            if method == 'TBMF':\n",
    "                patch.set_facecolor(\"none\")\n",
    "                patch.set_edgecolor(color)\n",
    "                patch.set_linewidth(2)\n",
    "            else:\n",
    "                patch.set_facecolor(\"none\")\n",
    "                patch.set_edgecolor(color)\n",
    "                patch.set_linewidth(1.5)\n",
    "\n",
    "        # Add individual points with jitter\n",
    "        for j, method in enumerate(methods_sorted):\n",
    "            method_ape = param_data[param_data['Method'] == method]['APE'].values\n",
    "            x_coords = np.random.normal(j + 1, 0.05, len(method_ape))\n",
    "\n",
    "            if method == 'TBMF':\n",
    "                ax.scatter(x_coords, method_ape, color=method_colors[method],\n",
    "                          alpha=0.7, s=55, edgecolors='black', linewidth=1.2,\n",
    "                          zorder=4, marker='o')\n",
    "            else:\n",
    "                ax.scatter(x_coords, method_ape, color=method_colors.get(method, '#808080'),\n",
    "                          alpha=0.65, s=45, edgecolors='black', linewidth=1,\n",
    "                          zorder=3)\n",
    "\n",
    "        # Enhanced title with ANOVA checkpoints and effect size\n",
    "        if param in param_anova_results:\n",
    "            anova_result = param_anova_results[param]\n",
    "            if anova_result['significance'] != 'ns':\n",
    "                title_text = f\"{param}\\n{anova_result['significance']}\"\n",
    "                if anova_result['p_value'] < 0.0001:\n",
    "                    title_text += \" (p < 0.0001)\"\n",
    "                else:\n",
    "                    title_text += f\" (p = {anova_result['p_value']:.4f})\"\n",
    "            else:\n",
    "                title_text = f\"{param}\\nns (p = {anova_result['p_value']:.3f})\"\n",
    "        else:\n",
    "            title_text = param\n",
    "\n",
    "        ax.set_title(title_text, fontsize=12, fontweight='bold', pad=15)\n",
    "\n",
    "        # Enhanced axis labels and formatting\n",
    "        ax.set_ylabel('APE (%)', fontsize=11, fontweight='bold')\n",
    "        ax.set_xlabel('Method (ordered by median APE)', fontsize=10)\n",
    "        ax.grid(True, alpha=0.3, linestyle='--')\n",
    "        ax.tick_params(axis='x', rotation=45, labelsize=9)\n",
    "        ax.tick_params(axis='y', labelsize=9)\n",
    "\n",
    "        # Set reasonable y-axis limits\n",
    "        all_values = param_data['APE'].values\n",
    "        y_max = np.percentile(all_values, 95)\n",
    "        ax.set_ylim(0,y_lims[i])\n",
    "\n",
    "        # Add significance brackets for TBMF comparisons if significant\n",
    "        if (param in param_anova_results and\n",
    "            param_anova_results[param]['significance'] != 'ns' and\n",
    "            'TBMF' in methods_sorted and\n",
    "            param_anova_results[param]['tbmf_comparisons']):\n",
    "\n",
    "            tbmf_pos = methods_sorted.index('TBMF') + 1\n",
    "            significant_comps = [comp for comp in param_anova_results[param]['tbmf_comparisons']\n",
    "                               if comp['Significant']]\n",
    "\n",
    "            y_max_plot = ax.get_ylim()[1]\n",
    "\n",
    "            for k, comp in enumerate(significant_comps):\n",
    "                other_method = comp['Group1'] if comp['Group1'] != 'TBMF' else comp['Group2']\n",
    "                if other_method in methods_sorted:\n",
    "                    other_pos = methods_sorted.index(other_method) + 1\n",
    "                    y = y_max_plot * (0.8 + k * 0.03)\n",
    "\n",
    "                    # Draw bracket\n",
    "                    ax.plot([min(tbmf_pos, other_pos), min(tbmf_pos, other_pos),\n",
    "                            max(tbmf_pos, other_pos), max(tbmf_pos, other_pos)],\n",
    "                           [y, y + y_max_plot * 0.02, y + y_max_plot * 0.02, y],\n",
    "                           'k-', linewidth=1.2, alpha=0.7)\n",
    "\n",
    "                    # Add significance text - show exact p-value if > 0.001\n",
    "                    if comp['P_adj'] > 0.001:\n",
    "                        # Show exact p-value for p > 0.001 (includes *, **, and ns)\n",
    "                        display_text = f\"p = {comp['P_adj']:.3f}\"\n",
    "                    else:\n",
    "                        # Show asterisks for p  0.001 (*** and ****)\n",
    "                        display_text = comp['Significance_Level']\n",
    "\n",
    "                    ax.text((tbmf_pos + other_pos) / 2, y + y_max_plot * 0.026,\n",
    "                           display_text,\n",
    "                           ha='center', va='bottom', fontweight='bold',\n",
    "                           color='red', fontsize=9)\n",
    "\n",
    "        # Style the axes\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_visible(True)\n",
    "            spine.set_color('black')\n",
    "            spine.set_linewidth(1)\n",
    "\n",
    "    plt.tight_layout(pad=3.0)\n",
    "\n",
    "    # Save the enhanced plot\n",
    "    plot_filename = f\"{save_path}parameter_wise_anova_comparison_tbmf.png\"\n",
    "    plt.savefig(plot_filename, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Enhanced parameter-wise ANOVA comparison plots saved to: {plot_filename}\")\n",
    "\n",
    "def save_parameter_anova_results(param_anova_results, save_path=\"/home/sahar/Models/Dinor_revision/new_phantom/dinor_train/code_addition/phanton_comp/\"):\n",
    "    \"\"\"\n",
    "    Save parameter-wise ANOVA checkpoints to CSV files\n",
    "    \"\"\"\n",
    "    # Create summary of all parameter ANOVA checkpoints\n",
    "    param_summary = []\n",
    "    tbmf_comparisons_all = []\n",
    "\n",
    "    for param, results in param_anova_results.items():\n",
    "        param_summary.append({\n",
    "            'Parameter': param,\n",
    "            'F_statistic': results['f_statistic'],\n",
    "            'P_value': results['p_value'],\n",
    "            'Significance': results['significance'],\n",
    "            'N_methods': len(results['methods']),\n",
    "            'Methods': ', '.join(results['methods']),\n",
    "            'TBMF_mean_APE': results['method_means'].get('TBMF', 'N/A'),\n",
    "            'TBMF_median_APE': results['method_medians'].get('TBMF', 'N/A')\n",
    "        })\n",
    "\n",
    "        # Collect TBMF comparisons\n",
    "        for comp in results['tbmf_comparisons']:\n",
    "            comp_copy = comp.copy()\n",
    "            comp_copy['Parameter'] = param\n",
    "            tbmf_comparisons_all.append(comp_copy)\n",
    "\n",
    "    # Save parameter summary\n",
    "    param_summary_df = pd.DataFrame(param_summary)\n",
    "    param_summary_filename = f\"{save_path}parameter_wise_anova_summary.csv\"\n",
    "    param_summary_df.to_csv(param_summary_filename, index=False)\n",
    "\n",
    "    # Save TBMF comparisons\n",
    "    if tbmf_comparisons_all:\n",
    "        tbmf_comparisons_df = pd.DataFrame(tbmf_comparisons_all)\n",
    "        tbmf_comparisons_filename = f\"{save_path}parameter_wise_tbmf_comparisons.csv\"\n",
    "        tbmf_comparisons_df.to_csv(tbmf_comparisons_filename, index=False)\n",
    "\n",
    "        print(f\"Parameter-wise TBMF comparisons saved to: {tbmf_comparisons_filename}\")\n",
    "\n",
    "    print(f\"Parameter-wise ANOVA summary saved to: {param_summary_filename}\")\n",
    "\n",
    "    return param_summary_df, pd.DataFrame(tbmf_comparisons_all) if tbmf_comparisons_all else None\n",
    "\n",
    "def run_comprehensive_tbmf_focused_anova_analysis():\n",
    "    \"\"\"\n",
    "    Main function to run comprehensive TBMF-focused ANOVA analysis (both overall and parameter-wise)\n",
    "    \"\"\"\n",
    "    # Calculate slice-based APE for all methods and parameters\n",
    "    ape_results, ape_df, param_names, param_units = calculate_all_ape_phantom_slice_based(\n",
    "        gt, tbmf_selective, y_nikita_6_masked, y_nikita_30_masked,\n",
    "        y_alex_nbmf_6_masked, y_alex_nbmf_30_masked,\n",
    "        y_alex_vbmf_6_masked, y_alex_vbmf_30_masked\n",
    "    )\n",
    "\n",
    "    # Perform overall ANOVA analysis focusing on TBMF\n",
    "    print(\"PERFORMING OVERALL ANOVA ANALYSIS...\")\n",
    "    overall_anova_results = perform_overall_anova_analysis_tbmf_focused(ape_df)\n",
    "\n",
    "    # Perform parameter-wise ANOVA analysis focusing on TBMF\n",
    "    print(\"\\nPERFORMING PARAMETER-WISE ANOVA ANALYSIS...\")\n",
    "    param_anova_results = perform_parameter_wise_anova_analysis_tbmf_focused(ape_df)\n",
    "\n",
    "    # Create overall comparison plot\n",
    "    print(\"\\nCREATING OVERALL COMPARISON PLOT...\")\n",
    "    create_overall_comparison_plot_with_anova_fixed(ape_df, overall_anova_results)\n",
    "\n",
    "    # Create parameter-wise comparison plots\n",
    "    print(\"\\nCREATING PARAMETER-WISE COMPARISON PLOTS...\")\n",
    "    create_enhanced_parameter_wise_plots(ape_df, param_anova_results)\n",
    "\n",
    "    # Create summary table\n",
    "    summary_table = create_ape_summary_table_slice_based(ape_df)\n",
    "\n",
    "    # Save parameter-wise ANOVA checkpoints\n",
    "    print(\"\\nSAVING PARAMETER-WISE RESULTS...\")\n",
    "    param_summary_df, tbmf_comparisons_df = save_parameter_anova_results(param_anova_results)\n",
    "\n",
    "    # Display summary statistics\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"COMPREHENSIVE SLICE-BASED APE SUMMARY STATISTICS\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Show summary for each parameter\n",
    "    for param in param_names[:6]:\n",
    "        param_summary = summary_table[summary_table['Parameter'] == param]\n",
    "        if not param_summary.empty:\n",
    "            print(f\"\\n{param}:\")\n",
    "            print(\"-\" * 40)\n",
    "            for _, row in param_summary.iterrows():\n",
    "                print(f\"  {row['Method']:10}: \"\n",
    "                      f\"Median={row['Median_APE']:6.2f}%, \"\n",
    "                      f\"Mean={row['Mean_APE']:6.2f}%, \"\n",
    "                      f\"IQR=[{row['Q25_APE']:5.2f}%, {row['Q75_APE']:5.2f}%], \"\n",
    "                      f\"N_slices={row['N_Slices']:2d}\")\n",
    "\n",
    "            # Show ANOVA checkpoints for this parameter\n",
    "            if param in param_anova_results:\n",
    "                anova_result = param_anova_results[param]\n",
    "                print(f\"    ANOVA: F = {anova_result['f_statistic']:.2f}, {anova_result['significance']}\")\n",
    "\n",
    "    # Save comprehensive checkpoints\n",
    "    save_path = \"/Dinor_revision/new_phantom/dinor_train/code_addition/phanton_comp/\"\n",
    "\n",
    "    # Save comprehensive APE data\n",
    "    ape_csv_filename = f\"{save_path}comprehensive_ape_slice_based_data_with_parameter_anova.csv\"\n",
    "    ape_df.to_csv(ape_csv_filename, index=False)\n",
    "\n",
    "    # Save summary statistics\n",
    "    summary_csv_filename = f\"{save_path}comprehensive_ape_summary_statistics_with_parameter_anova.csv\"\n",
    "    summary_table.to_csv(summary_csv_filename, index=False)\n",
    "\n",
    "    print(f\"\\nCOMPREHENSIVE RESULTS SAVED:\")\n",
    "    print(f\"- Comprehensive APE data: '{ape_csv_filename}'\")\n",
    "    print(f\"- Summary statistics: '{summary_csv_filename}'\")\n",
    "\n",
    "    return {\n",
    "        'ape_results': ape_results,\n",
    "        'ape_df': ape_df,\n",
    "        'summary_table': summary_table,\n",
    "        'overall_anova_results': overall_anova_results,\n",
    "        'param_anova_results': param_anova_results,\n",
    "        'param_summary_df': param_summary_df,\n",
    "        'tbmf_comparisons_df': tbmf_comparisons_df\n",
    "    }\n",
    "\n",
    "# Update the main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the comprehensive analysis (both overall and parameter-wise)\n",
    "    comprehensive_results = run_comprehensive_tbmf_focused_anova_analysis()"
   ],
   "id": "a70fcb2a6c9da01",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# ICC and image creation for comperisson of ph,fs, ksw and mM",
   "id": "bdf01bd29ff27a06"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ph_gt_tmbf_path = \"/comp/pH_maps_3D_test/scan12.h5\"\n",
    "mM_gt_tmbf_path = \"/comp/mM_maps_3D_test/scan12.h5\"\n",
    "ph_gt = h5py.File(ph_gt_tmbf_path)\n",
    "mM_gt = h5py.File(mM_gt_tmbf_path)\n",
    "keys_ph = list(ph_gt.keys())\n",
    "keys_mM = list(mM_gt.keys())\n",
    "ph_gt = ph_gt[keys_ph[-1]][:]\n",
    "mM_gt = mM_gt[keys_mM[-1]][:]\n",
    "gt_ph_mm = np.stack([ph_gt, mM_gt], axis=0)\n",
    "gt_ph_mm[gt_ph_mm < 2] = np.nan\n",
    "\n",
    "y_pred_path= \"/comp/y_pred_4D_pH_mM_scaled.h5\"\n",
    "y_pred = h5py.File(y_pred_path)\n",
    "y_pred_keys = list(y_pred.keys())\n",
    "y_pred = y_pred[y_pred_keys[-1]][:]\n",
    "y_pred = np.transpose(y_pred, (1,0, 2,3))\n",
    "y_pred[y_pred <2] = np.nan\n",
    "tbmf_ksw_fs = tbmf[:2]\n",
    "\n",
    "# Let's see what we're working with - show original data before any transformation\n",
    "fig, axes = plt.subplots(4, 2, figsize=(10, 5))\n",
    "\n",
    "# Store the image objects from imshow() calls\n",
    "im1 = axes[0,0].imshow(tbmf_ksw_fs[0,10], cmap=\"viridis\")\n",
    "axes[0,0].set_title('ksw Original')\n",
    "axes[0,0].axis(\"off\")\n",
    "\n",
    "im2 = axes[0,1].imshow(tbmf_ksw_fs[1,10], cmap=\"viridis\")\n",
    "axes[0,1].set_title('fs Original')\n",
    "axes[0,1].axis(\"off\")\n",
    "\n",
    "im3 = axes[1,0].imshow(y_pred[0,10], cmap=\"viridis\")\n",
    "axes[1,0].set_title('y_pred[0] (pH)')\n",
    "axes[1,0].axis(\"off\")\n",
    "\n",
    "im4 = axes[1,1].imshow(y_pred[1,10], cmap=\"viridis\")\n",
    "axes[1,1].set_title('y_pred[1] (mM)')\n",
    "axes[1,1].axis(\"off\")\n",
    "\n",
    "\n",
    "# Gt\n",
    "# Store the image objects from imshow() calls\n",
    "im5 = axes[2,0].imshow(tbmf_gt[0,10], cmap=\"viridis\")\n",
    "axes[2,0].set_title('ksw gt')\n",
    "axes[2,0].axis(\"off\")\n",
    "\n",
    "im6 = axes[2,1].imshow(tbmf_gt[1,10], cmap=\"viridis\")\n",
    "axes[2,1].set_title('fs gt')\n",
    "axes[2,1].axis(\"off\")\n",
    "\n",
    "im7 = axes[3,0].imshow(gt_ph_mm[0,10], cmap=\"viridis\")\n",
    "axes[3,0].set_title('GT (pH)')\n",
    "axes[3,0].axis(\"off\")\n",
    "\n",
    "im8 = axes[3,1].imshow(gt_ph_mm[1,10], cmap=\"viridis\")\n",
    "axes[3,1].set_title('(mM)')\n",
    "axes[3,1].axis(\"off\")\n",
    "\n",
    "\n",
    "# Add colorbars\n",
    "fig.colorbar(im1, ax=axes[0,0], shrink=0.8)\n",
    "fig.colorbar(im2, ax=axes[0,1], shrink=0.8)\n",
    "fig.colorbar(im3, ax=axes[1,0], shrink=0.8)\n",
    "fig.colorbar(im4, ax=axes[1,1], shrink=0.8)\n",
    "fig.colorbar(im5, ax=axes[2,0], shrink=0.8)\n",
    "fig.colorbar(im6, ax=axes[2,1], shrink=0.8)\n",
    "fig.colorbar(im7, ax=axes[3,0], shrink=0.8)\n",
    "fig.colorbar(im8, ax=axes[3,1], shrink=0.8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "c90c13025338590b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "\n",
    "# Set up the methods and their data - CORRECTED\n",
    "methods = {\n",
    "    'KSW': (tbmf_gt[0], tbmf_ksw_fs[0]),\n",
    "    'pH': (gt_ph_mm[0], y_pred[0]),\n",
    "    'fs': (tbmf_gt[1], tbmf_ksw_fs[1]),  # FIXED: was tbmf_ksw_fs[0], should be [1]\n",
    "    'mM': (gt_ph_mm[1], y_pred[1]),\n",
    "}\n",
    "\n",
    "# Parameter names\n",
    "param_names = [\n",
    "    r\"$K_{sw}$ (S$^{-1}$)\",\n",
    "    r\"pH\",\n",
    "    r\"$f_s$ (%)\",\n",
    "    r\"mM\",\n",
    "]\n",
    "\n",
    "# Create figure with black background\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "fig.patch.set_facecolor('black')  # Set black background for figure\n",
    "\n",
    "# Set black background for all subplots\n",
    "for i in range(2):\n",
    "    for j in range(4):\n",
    "        axes[i, j].set_facecolor('black')\n",
    "\n",
    "# Axis limits for each parameter [min, max]\n",
    "axis_limits = {\n",
    "    0: [0, 1400],      # K_ssw\n",
    "    1: [3.5, 7],       # pH - CORRECTED range\n",
    "    2: [0, 120],       # f_s\n",
    "    3: [0, 120],       # mM\n",
    "}\n",
    "\n",
    "results_summary = []\n",
    "\n",
    "# Process each method - CORRECTED loop structure\n",
    "for method_idx, (method_name, (data1, data2)) in enumerate(methods.items()):\n",
    "    print(f\"\\nProcessing {method_name}...\")\n",
    "\n",
    "    # Row 0: Statistical analysis\n",
    "    if method_idx < 4:  # We have 4 methods\n",
    "        ax = axes[0, method_idx]\n",
    "\n",
    "        # Extract parameter data\n",
    "        param1 = data1.copy()  # Ground truth\n",
    "        param2 = data2.copy()  # Prediction\n",
    "\n",
    "        print(f\"\\n{method_name}:\")\n",
    "        print(f\"  param1 range: [{np.nanmin(param1):.3f}, {np.nanmax(param1):.3f}]\")\n",
    "        print(f\"  param2 range: [{np.nanmin(param2):.3f}, {np.nanmax(param2):.3f}]\")\n",
    "        print(f\"  axis limits: {axis_limits[method_idx]}\")\n",
    "        print(f\"  Valid points: {np.sum(~np.isnan(param1) & ~np.isnan(param2))}\")\n",
    "\n",
    "        # Calculate ICC\n",
    "        try:\n",
    "            icc_value = slicewise_icc(param1, param2, icctype='ICC2')\n",
    "            print(f\"ICC for {method_name}: {icc_value:.3f}\")\n",
    "        except:\n",
    "            icc_value = np.nan\n",
    "\n",
    "        # Calculate Pearson correlation\n",
    "        mask = ~np.isnan(param1) & ~np.isnan(param2)\n",
    "        param1_clean = param1[mask]\n",
    "        param2_clean = param2[mask]\n",
    "\n",
    "        try:\n",
    "            if len(param1_clean) > 10:\n",
    "                pearson_r, pearson_p = stats.pearsonr(param1_clean, param2_clean)\n",
    "                print(f\"Pearson r for {method_name}: {pearson_r:.3f}, p={pearson_p:.3e}\")\n",
    "\n",
    "                # For plotting, subsample if too many points\n",
    "                if len(param1_clean) > 5000:\n",
    "                    subsample_idx = np.random.choice(len(param1_clean), 5000, replace=False)\n",
    "                    param1_plot = param1_clean[subsample_idx]\n",
    "                    param2_plot = param2_clean[subsample_idx]\n",
    "                else:\n",
    "                    param1_plot = param1_clean\n",
    "                    param2_plot = param2_clean\n",
    "\n",
    "                # Create scatter plot\n",
    "                ax.scatter(param1_plot, param2_plot, alpha=0.6, s=1.1, color='steelblue')\n",
    "\n",
    "                # Set axis limits\n",
    "                lims = axis_limits[method_idx]\n",
    "                ax.set_xlim(lims)\n",
    "                ax.set_ylim(lims)\n",
    "\n",
    "                # Add identity line\n",
    "                ax.plot(lims, lims, 'r--', alpha=0.8, linewidth=1)\n",
    "\n",
    "                # Add regression line\n",
    "                if not (np.isnan(pearson_r) or pearson_r == 0):\n",
    "                    slope, intercept = np.polyfit(param1_clean, param2_clean, 1)\n",
    "                    x_reg = np.array(lims)\n",
    "                    y_reg = slope * x_reg + intercept\n",
    "                    y_reg = np.clip(y_reg, lims[0], lims[1])\n",
    "                    ax.plot(x_reg, y_reg, 'orange', linewidth=1.5)\n",
    "\n",
    "                # Set labels and title with white color\n",
    "                ax.set_xlabel(f'Ground Truth {method_name}', color='white')\n",
    "                ax.set_ylabel(f'Predicted {method_name}', color='white')\n",
    "                ax.set_title(param_names[method_idx], fontweight='bold', color='white')\n",
    "\n",
    "                # Set tick colors to white\n",
    "                ax.tick_params(colors='white')\n",
    "\n",
    "                # Set spine colors to white\n",
    "                for spine in ax.spines.values():\n",
    "                    spine.set_color('white')\n",
    "\n",
    "                # Add statistics text\n",
    "                stats_text = f'r = {pearson_r:.3f}\\n'\n",
    "                if pearson_p < 0.001:\n",
    "                    stats_text += 'p < 0.001\\n'\n",
    "                else:\n",
    "                    stats_text += f'p = {pearson_p:.3f}\\n'\n",
    "                stats_text += f'ICC = {icc_value:.3f}\\n'\n",
    "\n",
    "                ax.text(0.05, 0.95, stats_text, transform=ax.transAxes,\n",
    "                       fontsize=10, verticalalignment='top',\n",
    "                       bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "                ax.grid(True, alpha=0.3, color='white')\n",
    "\n",
    "                # Store checkpoints\n",
    "                results_summary.append({\n",
    "                    'Method': method_name,\n",
    "                    'Parameter': param_names[method_idx],\n",
    "                    'Pearson_r': pearson_r,\n",
    "                    'Pearson_p': pearson_p,\n",
    "                    'ICC': icc_value,\n",
    "                    'N_points': len(param1_clean)\n",
    "                })\n",
    "            else:\n",
    "                ax.text(0.5, 0.5, 'Insufficient\\ndata', transform=ax.transAxes,\n",
    "                       ha='center', va='center', fontsize=10, color='white')\n",
    "                ax.set_title(param_names[method_idx], fontweight='bold', color='white')\n",
    "\n",
    "        except Exception as e:\n",
    "            ax.text(0.5, 0.5, 'Error in\\ncalculation', transform=ax.transAxes,\n",
    "                   ha='center', va='center', fontsize=10, color='white')\n",
    "            ax.set_title(param_names[method_idx], fontweight='bold', color='white')\n",
    "            print(f\"Error in {method_name}: {e}\")\n",
    "\n",
    "# Row 1: Example images\n",
    "slice_idx_p = 10\n",
    "slice_index_k = 8\n",
    "images = [\n",
    "    (tbmf_ksw_fs[0, slice_index_k], 'K_sw '),\n",
    "    (y_pred[0, slice_idx_p], 'pH'),\n",
    "    (tbmf_ksw_fs[1, slice_index_k], 'f_s'),\n",
    "    (y_pred[1, slice_idx_p], 'mM')\n",
    "]\n",
    "cbar = create_cmaps()\n",
    "cbar_list = [cbar[0], cbar[0], cbar[1], cbar[1]]\n",
    "vmin = [0,3,0,0]\n",
    "vmax = [1400,7,110,110]\n",
    "for i, (img_data, title) in enumerate(images):\n",
    "    ax = axes[1, i]\n",
    "\n",
    "    # Create image\n",
    "    im = ax.imshow(img_data, cmap=cbar_list[i], vmin=vmin[i], vmax=vmax[i])\n",
    "    ax.set_title(title, fontweight='bold', color='white')\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Get the position of the current subplot\n",
    "    pos = ax.get_position()\n",
    "\n",
    "    # Create colorbar axis below the image\n",
    "    cax = fig.add_axes([\n",
    "        pos.x0,           # Same left position as subplot\n",
    "        pos.y0 - 0.08,    # Below the subplot\n",
    "        pos.width,        # Same width as subplot\n",
    "        0.02              # Height of colorbar\n",
    "    ])\n",
    "\n",
    "    # Set colorbar background to black\n",
    "    cax.set_facecolor('black')\n",
    "\n",
    "    # Add colorbar\n",
    "    cbar = plt.colorbar(im, cax=cax, orientation='horizontal')\n",
    "    cbar.ax.tick_params(colors='white')  # White tick labels\n",
    "    cbar.outline.set_edgecolor('white')  # White outline\n",
    "\n",
    "# Adjust layout\n",
    "plt.subplots_adjust(top=0.93, bottom=0.15)  # Adjusted bottom to make room for colorbars\n",
    "\n",
    "\n",
    "# Uncomment these lines to save and create summary\n",
    "# # Save the plot\n",
    "save_path = \"/Dinor_revision/new_phantom/dinor_train/code_addition/phanton_comp/\"\n",
    "plt.savefig(f\"{save_path}/ICC_correlation_analysis_ph_mm_ksw_fs_black_bg.png\",\n",
    "            dpi=300, bbox_inches='tight', facecolor='black')\n",
    "#\n",
    "# Create summary table\n",
    "results_df = pd.DataFrame(results_summary)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY TABLE - pH, mM, K_sw, f_s Analysis\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if not results_df.empty:\n",
    "    print(\"\\nDetailed Results:\")\n",
    "    print(\"-\" * 60)\n",
    "    for _, row in results_df.iterrows():\n",
    "        print(f\"{row['Method']:>8}: ICC={row['ICC']:.3f}, \"\n",
    "              f\"r={row['Pearson_r']:.3f}, \"\n",
    "              f\"p={row['Pearson_p']:}, \"\n",
    "              f\"N={row['N_points']:,}\")\n",
    "\n",
    "    # Save checkpoints to CSV\n",
    "    csv_path = f\"{save_path}/correlation_icc_results_ph_mm_ksw_fs_black_bg.csv\"\n",
    "    results_df.to_csv(csv_path, index=False)\n",
    "    print(f\"\\nDetailed checkpoints saved to: {csv_path}\")"
   ],
   "id": "eb9b94dcd09f9965",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "ff04edcd35871d25",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
